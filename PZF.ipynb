{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07e407a",
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: signals based on lows\n",
    "# TODO: Pairplot for ETFs\n",
    "# TODO: Network pairs of ETFs for low or hi correlation\n",
    "############\n",
    "# https://stackoverflow.com/questions/69800749/using-python-to-get-holdings-and-allocation-of-etfs\n",
    "# conda env create -f environment.yml\n",
    "# conda install -f environment.yml\n",
    "# conda update -n base conda\n",
    "# conda env update --file environment.yml --prune\n",
    "# jupyter nbconvert --clear-output --inplace *.ipynb\n",
    "TEST = \"\"\n",
    "def set_test(tix: str):\n",
    "    global TEST\n",
    "    TEST = TEST or []\n",
    "    if type(TEST) == str:\n",
    "        TEST = TEST.split(\" \")\n",
    "    if type(tix) == str:\n",
    "        tix = tix.split(' ')\n",
    "    return ' '.join(sorted([r for r in set(TEST + tix) if bool(r)]))\n",
    "\n",
    "BENCH = 'VOO CRPT ^VIX '# KBWP PAVE IGM VGT QMOM URNM AMZA PKB=XHB SLX\n",
    "BROKERAGE = 'AIRR BETZ CLSE CRPT FPX HTUS IAI IGM KBWP KCE MGK PAVE PKB PSP RSHO SLX SPSM UTES VCR VDE VFH VFMO VGT VHT VIG VOO VOT VUG VYM XBI XHB XMMO XSMO'\n",
    "ROTH = 'AMZA BETZ CRPT IGM PAVE PKB QQQ SCHG SPYG URNM VDE VGT XHB' # Roth 2024.03.14. 04.01 -IVW VOO MGK VTI IUSG VUG\n",
    "\n",
    "# TEST = BENCH + \"BTC-USD ETH-USD\" + 'CLSE IAI KCE PSP XMMO XSMO UTES HTUS XBI XHB SPSM' # HRTS CBLS USE GCAD SLX VDE\n",
    "TEST = set_test(BENCH)\n",
    "TEST = set_test(BROKERAGE)\n",
    "TEST = set_test(ROTH)\n",
    "\n",
    "print(\"https://www.etfdb.com\")\n",
    "print(\"https://www.etfrc.com/funds/overlap.php\")\n",
    "print(TEST)\n",
    "start = '2020-11-03'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05b34e8-3c63-4b32-a7a2-d5702b8c2785",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e3e854-f95c-4411-8dbb-ef9bf2035539",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import libraries and pull data\n",
    "import datetime\n",
    "import warnings\n",
    "import os\n",
    "import importlib\n",
    "import re\n",
    "import json\n",
    "import textwrap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import pandas_ta as ta\n",
    "import yfinance as yf\n",
    "#import quantstats as qs\n",
    "import seaborn as sns\n",
    "import cufflinks as cf\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from ipywidgets import widgets, interact, interactive\n",
    "from scipy import stats\n",
    "#from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import Dense, LSTM, Activation\n",
    "from IPython.display import display, clear_output, HTML\n",
    "# from yahooquery import Ticker, Screener\n",
    "# from pyvis import network as net\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "cf.go_offline()\n",
    "pio.renderers.default = 'iframe'\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"yfinance\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"cufflinks\")\n",
    "warnings.filterwarnings(\"ignore\", \"is_categorical_dtype\")\n",
    "warnings.filterwarnings(\"ignore\", \"use_inf_as_na\")\n",
    "warnings.filterwarnings(\"ignore\", \"warn_singular\")\n",
    "warnings.simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "template = 'plotly_dark'\n",
    "pd.options.display.float_format = \"{:,.2f}\".format\n",
    "\n",
    "# EPOCH=64\n",
    "# EPOCH=32\n",
    "NOP = 20000 # Number of random portfolio sets\n",
    "risk_free_return = .05\n",
    "ichimoku_window = 26\n",
    "rwindow = 6 # How many trading days to aggregate MACD/ RSI for\n",
    "cutoff = 16 # % of samples falling below that satisfy criteria for MACD/ RSI\n",
    "cofactor = 6 # fraction of ^ to generate buy/sell signal\n",
    "model = 'Sharpe'\n",
    "categories = {\n",
    "    # \"ai\": AI,\n",
    "    # \"base\": BASE,\n",
    "    # \"construction\": CONSTRUCTION,\n",
    "    # \"crypto\": CRYPTO,\n",
    "    # \"div\": DIV,\n",
    "    # \"energy\": ENERGY,\n",
    "    # \"growth\": GROWTH,\n",
    "    # \"infra\": INFRA,\n",
    "    # \"insurance\": INSURANCE,\n",
    "    # \"internationals\": INTERNATIONALS,\n",
    "    # \"sectors\": SECTORS,\n",
    "}\n",
    "symbol_map={'triangle-up':'triangle-up', 'triangle-down':'triangle-down', 'square': 'square', 'circle':'circle'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4376d56a-1452-43ea-9176-e9091a997ef0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def install_if_missing(package):\n",
    "    try:\n",
    "        importlib.import_module(package)\n",
    "    except ImportError:\n",
    "        import subprocess\n",
    "        import sys\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "def alpha_arbitrage(v, msk):\n",
    "    df = pd.DataFrame()\n",
    "    # drop over 1 months\n",
    "    # drop over 1 months vs VOO\n",
    "    # rise over next X months\n",
    "    # rise over next X months vs VOO\n",
    "    df['discount.beta'] = (edf[v]['Adj Close'].pct_change(22, fill_method=None) - idx['Adj Close','VOO'].pct_change(22, fill_method=None))*100\n",
    "    df['ft.prc'] = edf[v]['Adj Close'].pct_change(-22, fill_method=None) * 100\n",
    "    df['ft.alpha'] = (edf[v]['Adj Close'].pct_change(-22, fill_method=None) - idx['Adj Close','VOO'].pct_change(-22, fill_method=None))*100\n",
    "    return {v: {'ft.rtn': round(float(df[msk]['ft.prc'].describe()['mean']), 2), 'outperform': round(float(df[msk]['ft.alpha'].describe()['mean']), 2), 'count': int(df[msk]['ft.alpha'].describe()['count'])}}\n",
    "\n",
    "def rsi_target(df1, prc=25):\n",
    "    df = df1.copy()\n",
    "    pt={v:0 for v in df['Adj Close'].columns}\n",
    "    for _ in range(100):\n",
    "        df.loc[df['Adj Close'].index[-1], 'Adj Close'] = df.iloc[-1].loc['Adj Close'].values * .99\n",
    "        cv = calculate_rsi(df).tail(1)\n",
    "        for v in cv:\n",
    "            if bool(pt[v]):\n",
    "                continue\n",
    "            tv = df.iloc[-1]['Adj Close', v].round(2)\n",
    "            pt[v] = pt[v] if cv[v].iloc[-1] > prc else float(tv)\n",
    "    return pt\n",
    "\n",
    "def compare_values_ichi(row):\n",
    "    if row['Close'] > max([row['senkou_span_a'], row['senkou_span_b']]):\n",
    "        if row['senkou_span_a'] > row['senkou_span_b']:\n",
    "            return 'top left'\n",
    "        elif row['senkou_span_a'] < row['senkou_span_b']:\n",
    "            return 'top right'\n",
    "        return 'top center'\n",
    "    elif row['Close'] < min([row['senkou_span_a'], row['senkou_span_b']]):\n",
    "        if row['senkou_span_a'] < row['senkou_span_b']:\n",
    "            return 'bottom left'\n",
    "        elif row['senkou_span_a'] > row['senkou_span_b']:\n",
    "            return 'bottom right'\n",
    "        return 'bottom center'\n",
    "    else:\n",
    "        return 'middle center'\n",
    "\n",
    "def calc_positions_ichimoku(d):\n",
    "    global idx\n",
    "    columns = d['Low'].columns\n",
    "    # Adding signals for buy/ sell\n",
    "    condition = np.where(\n",
    "        (d['tenkan_sen'] > d['kijun_sen']) &\n",
    "        (d['Close'] > d['tenkan_sen']) &\n",
    "        (\n",
    "            ((d['Close'] > d['senkou_span_a']) & (d['Close'] > d['senkou_span_b'])) |\n",
    "            ((d['Close'] < d['senkou_span_a']) & (d['Close'] < d['senkou_span_b']))\n",
    "        ), 1, 0\n",
    "    )\n",
    "    sgn = pd.DataFrame(condition, columns=columns, index=d.index)\n",
    "    sgn.columns = pd.MultiIndex.from_product([['signal_ichimoku'], columns])\n",
    "    pos = sgn.diff().fillna(0)\n",
    "    pos.columns = pd.MultiIndex.from_product([['position_ichimoku'], columns])\n",
    "    idx.drop(columns='signal_ichimoku', inplace=True, errors='ignore')\n",
    "    idx.drop(columns='position_ichimoku', inplace=True, errors='ignore')\n",
    "    idx = idx.join(pos)\n",
    "    idx = idx.join(sgn)\n",
    "\n",
    "def calc_positions_rsi(d):\n",
    "    global idx\n",
    "    columns = d['Low'].columns\n",
    "    # Adding signals for buy/ sell\n",
    "    indicator='RSI'\n",
    "    period=42\n",
    "    sgn = pd.DataFrame(np.where(d[indicator].rolling(window=period).mean() - idx[indicator] - .3 < 0, 0, 1), columns=columns, index=d.index)\n",
    "    sgn.columns = pd.MultiIndex.from_product([['signal_rsi'], columns])\n",
    "    pos = sgn.diff().fillna(0)\n",
    "    pos.columns = pd.MultiIndex.from_product([['position_rsi'], columns])\n",
    "    idx.drop(columns='signal_rsi', inplace=True, errors='ignore')\n",
    "    idx.drop(columns='position_rsi', inplace=True, errors='ignore')\n",
    "    idx = idx.join(pos)\n",
    "    idx = idx.join(sgn)\n",
    "    \n",
    "def calc_positions_ema(d):\n",
    "    global idx\n",
    "    columns = d['Low'].columns\n",
    "    # Adding signals for buy/ sell\n",
    "    sgn = pd.DataFrame(np.where(d['EMAW'] > d['EMAM'], 1, 0), columns=columns, index=d.index)\n",
    "    sgn.columns = pd.MultiIndex.from_product([['signal_ema'], columns])\n",
    "    pos = sgn.diff().fillna(0)\n",
    "    pos.columns = pd.MultiIndex.from_product([['position_ema'], columns])\n",
    "    idx.drop(columns='signal_ema', inplace=True, errors='ignore')\n",
    "    idx.drop(columns='position_ema', inplace=True, errors='ignore')\n",
    "    idx = idx.join(pos)\n",
    "    idx = idx.join(sgn)\n",
    "\n",
    "def price_bands(period = 42, multiplier = 1.8): # Calculate price bands\n",
    "    global idx\n",
    "    \n",
    "    columns = idx['Low'].columns\n",
    "    \n",
    "    std = idx['Adj Close'].rolling(window=period).std()\n",
    "    std.columns = pd.MultiIndex.from_product([['STD'], columns])\n",
    "    idx = idx.join(std)\n",
    "    \n",
    "    ma = idx['Adj Close'].rolling(window=period).mean()\n",
    "    ma.columns = pd.MultiIndex.from_product([['MA'], columns])\n",
    "    idx = idx.join(ma)\n",
    "    \n",
    "    uband = idx['MA'] + multiplier * idx['STD']\n",
    "    uband.columns = pd.MultiIndex.from_product([['UBAND'], columns])\n",
    "    idx = idx.join(uband)\n",
    "    \n",
    "    lband = idx['MA'] - multiplier * idx['STD']\n",
    "    lband.columns = pd.MultiIndex.from_product([['LBAND'], columns])\n",
    "    idx = idx.join(lband)\n",
    "\n",
    "    emaw = idx['Adj Close'].ewm(span=5, adjust=False).mean()\n",
    "    emaw.columns = pd.MultiIndex.from_product([['EMAW'], columns])\n",
    "    idx = idx.join(emaw)\n",
    "    \n",
    "    emam = idx['Adj Close'].ewm(span=21, adjust=False).mean()\n",
    "    emam.columns = pd.MultiIndex.from_product([['EMAM'], columns])\n",
    "    idx = idx.join(emam)\n",
    "    \n",
    "    # Moving Average Convergence Divergence\n",
    "    mdl = idx['EMAM'] - idx['EMAW']\n",
    "    sgl = mdl.ewm(span=16, adjust=False).mean()\n",
    "    mdh = sgl - mdl\n",
    "    mdh.columns = pd.MultiIndex.from_product([['MACD'], columns])\n",
    "    idx = idx.join(mdh)\n",
    "\n",
    "    # Relative Strength Index\n",
    "    rsi = calculate_rsi(idx)/25-2\n",
    "    rsi.columns = pd.MultiIndex.from_product([['RSI'], columns])\n",
    "    idx = idx.join(rsi)\n",
    "    \n",
    "    idx = calc_ichimoku(idx)\n",
    "    calc_positions_ichimoku(idx)\n",
    "    calc_positions_ema(idx)\n",
    "    calc_positions_rsi(idx)\n",
    "\n",
    "    summary['UBAND'] = idx['UBAND'].iloc[-1]\n",
    "    summary['Adj Close'] = idx['Adj Close'].iloc[-1]\n",
    "    summary['LBAND'] = idx['LBAND'].iloc[-1]\n",
    "\n",
    "    rsi_prc = idx.rolling(rwindow).mean()['RSI'].rank(pct=True) * 100\n",
    "    macd_prc = idx.rolling(rwindow).mean()['MACD'].rank(pct=True) * 100\n",
    "    if '^VIX' in macd_prc.columns:\n",
    "        macd_prc['^VIX'] = 100 - macd_prc['^VIX']\n",
    "        rsi_prc['^VIX'] = 100 - rsi_prc['^VIX']\n",
    "    rsi_prc.columns = pd.MultiIndex.from_product([['RSI_prc'], columns])\n",
    "    idx = idx.join(rsi_prc)\n",
    "    macd_prc.columns = pd.MultiIndex.from_product([['MACD_prc'], columns])\n",
    "    idx = idx.join(macd_prc)\n",
    "    for indicator in ['MACD_prc', 'RSI_prc']:\n",
    "        summary[indicator] = idx[indicator].iloc[-1]\n",
    "        \n",
    "    columns = idx['Low'].columns\n",
    "    conditions = [\n",
    "        idx['tenkan_sen'] > idx['kijun_sen'],\n",
    "        idx['tenkan_sen'] == idx['kijun_sen'],\n",
    "        idx['tenkan_sen'] < idx['kijun_sen']\n",
    "    ]\n",
    "    choices = ['triangle-up', 'square', 'triangle-down']\n",
    "    shape = np.select(conditions, choices, default='circle')\n",
    "    shape = pd.DataFrame(np.select(conditions, choices, default='circle'))\n",
    "    shape.columns = pd.MultiIndex.from_product([['symbol'], columns])\n",
    "    shape.index=idx.index\n",
    "    idx = idx.join(shape)\n",
    "    \n",
    "    trend = (\n",
    "        (idx['Close'] > idx['tenkan_sen']) & (idx['tenkan_sen'] > idx['kijun_sen'])\n",
    "    )|(\n",
    "        (idx['Close'] < idx['tenkan_sen']) & (idx['tenkan_sen'] < idx['kijun_sen'])\n",
    "    )\n",
    "    trend = (trend).astype(int)/2+.5\n",
    "    trend.columns = pd.MultiIndex.from_product([['trend'], columns])\n",
    "    trend.index=idx.index\n",
    "    idx = idx.join(trend)\n",
    "    \n",
    "def calculate_rsi(data, window=10):\n",
    "    delta = data['Adj Close'].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    rsi = 100 - (100 / (gain / loss + 1))\n",
    "    return rsi\n",
    "\n",
    "def fillcol(d):\n",
    "    np.where(d['senkou_span_a'] > d['senkou_span_b'], 'green', 'red')\n",
    "\n",
    "def calc_ichimoku(d, tenkan_window=9, kijun_window=ichimoku_window, senkou_span_b_window=ichimoku_window*2, cloud_displacement=ichimoku_window, chikou_shift=ichimoku_window):\n",
    "    last_date = d['Low'].dropna().index[-1]\n",
    "    if type(d['Low']) == pd.core.frame.DataFrame:\n",
    "        columns = d['Low'].columns\n",
    "        # Tenkan-sen (Conversion Line): (9-period high + 9-period low)/2))\n",
    "        nine_period_high = d['High'].rolling(window= tenkan_window).max()\n",
    "        nine_period_low = d['Low'].rolling(window= tenkan_window).min()\n",
    "        tenkan_sen = (nine_period_high + nine_period_low) /2\n",
    "        tenkan_sen.columns = pd.MultiIndex.from_product([['tenkan_sen'], columns])\n",
    "        d = d.join(tenkan_sen)\n",
    "\n",
    "        # Kijun-sen (Base Line): (26-period high + 26-period low)/2))\n",
    "        period26_high = d['High'].rolling(window=kijun_window).max()\n",
    "        period26_low = d['Low'].rolling(window=kijun_window).min()\n",
    "        kijun_sen = (period26_high + period26_low) / 2\n",
    "        kijun_sen.columns = pd.MultiIndex.from_product([['kijun_sen'], columns])\n",
    "        d = d.join(kijun_sen)\n",
    "\n",
    "        # Senkou Span A (Leading Span A): (Conversion Line + Base Line)/2))\n",
    "        senkou_span_a = ((d['tenkan_sen'] + d['kijun_sen']) / 2).shift(cloud_displacement)\n",
    "        senkou_span_a.columns = pd.MultiIndex.from_product([['senkou_span_a'], columns])\n",
    "        d = d.join(senkou_span_a)\n",
    "\n",
    "        # Senkou Span B (Leading Span B): (52-period high + 52-period low)/2))\n",
    "        period52_high = d['High'].rolling(window=senkou_span_b_window).max()\n",
    "        period52_low = d['Low'].rolling(window=senkou_span_b_window).min()\n",
    "        senkou_span_b = ((period52_high + period52_low) / 2).shift(cloud_displacement)\n",
    "        senkou_span_b.columns = pd.MultiIndex.from_product([['senkou_span_b'], columns])\n",
    "        d = d.join(senkou_span_b)\n",
    "\n",
    "        # The most current closing price plotted 26 time periods behind (optional)\n",
    "        chikou_span = d['Close'].shift(-chikou_shift)\n",
    "        chikou_span.columns = pd.MultiIndex.from_product([['chikou_span'], columns])\n",
    "        d = d.join(chikou_span)\n",
    "\n",
    "    else:\n",
    "        # Step 2: Create a new date range for the next 26 business days\n",
    "        new_dates = pd.date_range(start=last_date+pd.Timedelta(days=1), periods=kijun_window, freq=pd.offsets.BDay())\n",
    "        # Step 3: Convert the DatetimeIndex to a DateIndex (i.e., remove the time part)\n",
    "        new_dates = new_dates.date  # This will convert the index to date type\n",
    "        # Step 4: Create a new dataframe with the new business dates (as date type index)\n",
    "        new_data = pd.DataFrame(index=new_dates)\n",
    "        # Step 5: Append the new rows to the original dataframe\n",
    "        d = pd.concat([d, new_data])\n",
    "\n",
    "        # Senkou Span A (Leading Span A): (Conversion Line + Base Line)/2))\n",
    "        d['senkou_span_a'] = ((d['tenkan_sen'] + d['kijun_sen']) / 2).shift(cloud_displacement)\n",
    "\n",
    "        # Senkou Span B (Leading Span B): (52-period high + 52-period low)/2))\n",
    "        period52_high = d['High'].rolling(window=senkou_span_b_window).max()\n",
    "        period52_low = d['Low'].rolling(window=senkou_span_b_window).min()\n",
    "        d['senkou_span_b'] = ((period52_high + period52_low) / 2).shift(cloud_displacement)\n",
    "\n",
    "        # The most current closing price plotted 26 time periods behind (optional)\n",
    "        d['chikou_span'] = d['Close'].shift(-chikou_shift)\n",
    "    return d\n",
    "    \n",
    "def plot2_ichimoku(d, ticker_name='', INCREASING_COLOR='green', DECREASING_COLOR='red', show_rangeslider=False):\n",
    "    fig = go.Figure(data=[go.Candlestick(x=d.index, open=d.Open, high=d.High, low=d.Low, close=d.Close,\n",
    "         increasing_line_color=INCREASING_COLOR, decreasing_line_color=DECREASING_COLOR, showlegend=False)])\n",
    "    kw = {'x': d.index, 'type': 'scatter', 'mode':'lines', 'showlegend': False}#'visible':'legendonly'}\n",
    "\n",
    "    # Add TenkenSen to plot\n",
    "    fig.add_trace(go.Scatter(y=d['tenkan_sen'], name='tenkan_sen', line=dict(color='#33BDFF', width=1), **kw))\n",
    "    # Add kijun_sen to plot\n",
    "    fig.add_trace(go.Scatter(y=d['kijun_sen'], name='kijun_sen', line=dict(color='#F1F316', width=1), **kw))\n",
    "\n",
    "    kw = {'x': d.index, 'type': 'scatter', 'mode':'lines', 'showlegend': False}\n",
    "    # Add senkou_span_a to plot\n",
    "    fig.add_trace(go.Scatter(y=np.where(d['senkou_span_a'] > d['senkou_span_b'], d['senkou_span_a'], d['senkou_span_b']), name='senkou_span_max', line=dict(color='#228B22', width=0), **kw))\n",
    "    fig.add_trace(go.Scatter(\n",
    "        y=d['senkou_span_b'], \n",
    "        fill='tonexty',\n",
    "        fillcolor='rgba(0, 128, 0, 0.25)',\n",
    "        line=dict(color='rgba(0, 128, 0, 0.1)'),\n",
    "        name='senkou_span_a above',\n",
    "        **kw\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Scatter(y=np.where(d['senkou_span_b'] > d['senkou_span_a'], d['senkou_span_b'], d['senkou_span_a']), name='senkou_span_min', line=dict(color='#228B22', width=0), **kw))\n",
    "    fig.add_trace(go.Scatter(\n",
    "        y=d['senkou_span_a'], \n",
    "        fill='tonexty',\n",
    "        fillcolor='rgba(128, 0, 0, 0.25)',\n",
    "        line=dict(color='rgba(128, 0, 0, 0.1)'),\n",
    "        name='senkou_span_b above',\n",
    "        **kw\n",
    "    ))\n",
    "\n",
    "    # Add chikou_span to plot\n",
    "    fig.add_trace(go.Scatter(y=d['chikou_span'], name='chikou_span', line=dict(color='#D105F5', width=1), **kw))\n",
    "    fig.update_layout(xaxis_rangeslider_visible=show_rangeslider)\n",
    "\n",
    "    fig.update_layout(\n",
    "        # title='Ichimoku',\n",
    "        yaxis_title=f'{ticker_name} Price',\n",
    "        xaxis_title='Date',\n",
    "        legend=dict(orientation='h', y=0.1, x=0.1, yanchor='top'),\n",
    "        margin=dict(t=40, b=40, r=40, l=40),\n",
    "        yaxis=dict(type='log'),\n",
    "        template=template,\n",
    "    )\n",
    "    return fig #.show()\n",
    "\n",
    "def ann_risk_return(df):\n",
    "    rdf = df.agg([\"mean\", \"std\"]).T\n",
    "    rdf.columns = [\"Return\", \"Risk\"]\n",
    "    rdf.Return = (df.iloc[-1] / df.iloc[0]) ** (1/(((df.index[-1]-df.index[0]).days)/365)) - 1\n",
    "    rdf.Risk = rdf.Risk * np.sqrt(252)\n",
    "    return rdf\n",
    "\n",
    "def get_sortino(df):\n",
    "    returns = df.pct_change(1).dropna()\n",
    "    downside_returns = returns[returns < 0]\n",
    "    downside_std = np.std(downside_returns, axis=0)\n",
    "    sortino_ratio = returns.mean() / downside_std\n",
    "    return sortino_ratio\n",
    "\n",
    "def get_parent(ticker):\n",
    "    for parent in categories:\n",
    "        if ticker in (categories[parent]).split():\n",
    "            return parent\n",
    "    return summary.loc[ticker,'category']\n",
    "\n",
    "def h_max(s):\n",
    "    try:\n",
    "        is_max = s.astype('float') == s.max()\n",
    "        return ['color: green' if cell else '' for cell in is_max]\n",
    "    except:\n",
    "        return ['' for cell in s]\n",
    "\n",
    "def h_min(s):\n",
    "    try:\n",
    "        is_min= s.astype('float') == s.min()\n",
    "        return ['color: blue' if cell else '' for cell in is_min]\n",
    "    except:\n",
    "        return ['' for cell in s]\n",
    "\n",
    "def h_bull(s):\n",
    "    try:\n",
    "        is_bs = s.astype('str').str.contains('ullish|Buy', regex=True) & ~s.astype('str').str.contains('earish|Sell', regex=True) & ~s.astype('str').str.contains('Weak') & ~s.astype('str').str.contains(' one ')\n",
    "        return ['color: green' if cell else '' for cell in is_bs]\n",
    "    except:\n",
    "        return ['' for cell in s]\n",
    "\n",
    "def h_bear(s):\n",
    "    try:\n",
    "        is_bs = s.astype('str').str.contains('earish|Sell', regex=True) & ~s.astype('str').str.contains('ullish|Buy', regex=True) & ~s.astype('str').str.contains('Weak') & ~s.astype('str').str.contains(' one ')\n",
    "        return ['color: red' if cell else '' for cell in is_bs]\n",
    "    except:\n",
    "        return ['' for cell in s]\n",
    "    \n",
    "def de_macd(fund):\n",
    "    df = pd.DataFrame(idx['Adj Close'][fund].copy())\n",
    "    df['Adj Close'] = df[fund]\n",
    "    step = df.loc[df.index[-1], 'Adj Close'] * .002\n",
    "    if (idx['MACD_prc'][fund].rank(pct=True)*100 < cutoff/cofactor).iloc[-1]:\n",
    "        return df.loc[df.index[-1], 'Adj Close']\n",
    "    for i in range(100):\n",
    "        df.loc[df.index[-1], 'Adj Close'] -= step\n",
    "        df['emaw'] = df['Adj Close'].ewm(span=5, adjust=False).mean()\n",
    "        df['emam'] = df['Adj Close'].ewm(span=21, adjust=False).mean()\n",
    "        df['mdl'] = df['emam'] - df['emaw']\n",
    "        df['sgl'] = df['mdl'].ewm(span=16, adjust=False).mean()\n",
    "        df['mdh'] = df['sgl'] - df['mdl']\n",
    "        if df['mdh'].rank(pct=True).iloc[-1]*100 < cutoff/ cofactor:\n",
    "            return df.loc[df.index[-1], 'Adj Close']\n",
    "    return\n",
    "\n",
    "def de_rsi(fund, window=10):\n",
    "    df = pd.DataFrame(idx['Adj Close'][fund].copy())\n",
    "    df['Adj Close'] = df[fund]\n",
    "    step = df.loc[df.index[-1], 'Adj Close'] * .002\n",
    "    if (idx['RSI_prc'][fund].rank(pct=True)*100 < cutoff/cofactor).iloc[-1]:\n",
    "        pass #return df.loc[df.index[-1], 'Adj Close']\n",
    "    for i in range(100):\n",
    "        df.loc[df.index[-1], 'Adj Close'] -= step\n",
    "        delta = df['Adj Close'].diff()\n",
    "        gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "        loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "        rsi = 100 - (100 / (gain / loss + 1))\n",
    "        if (rsi.rank(pct=True)*100 ).iloc[-1] < cutoff/ cofactor:\n",
    "            return df.loc[df.index[-1], 'Adj Close']\n",
    "    return\n",
    "\n",
    "def annualize(fund, days, x=-1):\n",
    "    idx.index = idx_index\n",
    "    yfraction = (((pd.to_datetime(idx['Adj Close'][fund].index[x]).date()-pd.to_datetime(idx['Adj Close'][fund].index[x-days-1]).date()).days)/365)\n",
    "    rf = (idx['Adj Close'][fund].iloc[x] / idx['Adj Close'][fund].iloc[x-days-1]) ** (1/yfraction) - 1\n",
    "    rv = (idx['Adj Close']['VOO'].iloc[x] / idx['Adj Close']['VOO'].iloc[x-days-1]) ** (1/yfraction) - 1\n",
    "    return rf - rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5155b05-b64c-4f4e-a6e2-d277efaec341",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "install_if_missing('yahooquery')\n",
    "install_if_missing('pyvis')\n",
    "from yahooquery import Ticker, Screener\n",
    "from pyvis import network as net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be94d7a-689b-4aff-8eba-0ef3a22ea1db",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tix = \" \".join(sorted(set(TEST.split())))\n",
    "for _ in range(3):\n",
    "    kw = {'start': start, 'auto_adjust': False}\n",
    "    end = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    # TODO: change theme if dropped data\n",
    "    \n",
    "    # kw['end'] = '2025-01-17'\n",
    "    idx = yf.download(tix, **kw)\n",
    "    idx.index = idx.index.date\n",
    "    if idx['Adj Close'].index[0] != idx['Adj Close'].dropna().index[0]:\n",
    "        start = idx['Adj Close'].dropna().index[0]\n",
    "        print(f\"\\nCommon start: {start}\")\n",
    "        display(idx['Adj Close'][:start].fillna(''))\n",
    "        idx = idx.loc[start:]\n",
    "    adj_prices = idx['Adj Close'].copy()\n",
    "    if any(adj_prices.iloc[-1].isna()):\n",
    "        print(\"Missing data from today!!!\")\n",
    "        columns_with_na_in_last_row = adj_prices.columns[adj_prices.isna().iloc[-1]].tolist()\n",
    "        if adj_prices.loc[:,~adj_prices.iloc[-1].isna()].columns.size == 1 and adj_prices.loc[:,~adj_prices.iloc[-1].isna()].columns[0] == '^VIX':\n",
    "            print(\"One ticker returned for VIX!!!\")\n",
    "            columns_with_na_in_last_row = ['^VIX']\n",
    "            tix = adj_prices.columns[adj_prices.isna().iloc[-1]].tolist()\n",
    "            continue\n",
    "        print(f\"Drop {columns_with_na_in_last_row}\" + 10*\"\\n\")\n",
    "        tix = adj_prices.columns[~adj_prices.isna().iloc[-1]].tolist()\n",
    "    else:\n",
    "        break\n",
    "display(adj_prices.tail())\n",
    "display(100*adj_prices.pct_change(1, fill_method=None).tail())\n",
    "prices = idx['Adj Close'].div(idx['Adj Close'].iloc[0]).mul(100)\n",
    "ret = prices.pct_change().dropna()\n",
    "summary = pd.DataFrame(index=idx['Adj Close'].columns)\n",
    "price_bands() # Calculate price bands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89bd848-a906-418e-89da-5f47b2af0e84",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Radar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cac752-dff7-46f8-9365-cbb77943b702",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x=-0\n",
    "if bool(x):\n",
    "    print((f\"!!! NOT USING default today's date!!!\"+\"\\n\")*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37a03d1-72f6-43a3-b2a6-8dba5b870379",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if type(x) == str:\n",
    "    x=0\n",
    "x-=1 # Use previous day's data\n",
    "idx_index = idx.index\n",
    "idx.index = idx.index.astype(str)\n",
    "trend = (\n",
    "    (idx['Close'] > idx['tenkan_sen']) & (idx['tenkan_sen'] > idx['kijun_sen'])\n",
    ")|(\n",
    "    (idx['Close'] < idx['tenkan_sen']) & (idx['tenkan_sen'] < idx['kijun_sen'])\n",
    ")\n",
    "cloudposition = [idx.swaplevel(1,0, axis=1)[v].apply(compare_values_ichi, axis=1).iloc[x] for v in idx['Low'].columns]\n",
    "x_idx = idx['MACD_prc'].iloc[x] + np.random.uniform(-0.1, 0.1, size=len(idx['Close'].columns))\n",
    "y_idx = idx['RSI_prc'].iloc[x] + np.random.uniform(-0.1, 0.1, size=len(idx['Close'].columns))\n",
    "g = px.scatter(\n",
    "    idx.iloc[x]['Adj Close'],\n",
    "    text=[i.upper() if v else i.lower() for i, v in idx['signal_ichimoku'].iloc[x].items()],\n",
    "    x=x_idx,\n",
    "    y=y_idx,\n",
    "    range_x=[0, 100],\n",
    "    range_y=[0, 100],\n",
    "    hover_name=[i.upper() if v else i.lower() for i, v in idx['signal_ichimoku'].iloc[x].items()],\n",
    "    hover_data=[idx.iloc[x]['Adj Close'], rsi_target(idx[:x]).values()],\n",
    "    color=idx['Adj Close'].pct_change().iloc[x].values*100, color_continuous_scale='RdYlGn', color_continuous_midpoint=0.0,\n",
    "    title=f\"RSI vs MACD Rankings as of {idx.index[x]}\", template=template,\n",
    "    symbol=idx.iloc[x]['symbol'], symbol_map=symbol_map,\n",
    ")\n",
    "\n",
    "for fund in summary.index:\n",
    "    if fund == '^VIX':\n",
    "        continue\n",
    "    for i, days in enumerate([1, 5, 21, 63, 252, 504]):\n",
    "        if days-x > len(idx.index):\n",
    "            days = len(idx.index)-1+x\n",
    "        kw = {\n",
    "            'type': 'line',\n",
    "            'x0': x_idx[fund],\n",
    "            'y0': y_idx[fund],\n",
    "            'x1': idx['MACD_prc'].iloc[x][fund]+i/2,\n",
    "            'y1': idx['RSI_prc'].iloc[x][fund]+min([annualize(fund, days, x), 25])*5,\n",
    "            'line': dict(color=f\"rgba(255, 255, 255, {.2+0.1*i})\", width=.5+2/(1+i))\n",
    "        }\n",
    "        g.add_shape(**kw)\n",
    "\n",
    "g.add_shape(type='line', x0=50, y0=50, x1=100, y1=50, line=dict(color='red', dash='dash'))\n",
    "g.add_shape(type='line', x0=50, y0=50, x1=50, y1=100, line=dict(color='red', dash='dash'))\n",
    "g.add_shape(type='line', x0=0, y0=50, x1=50, y1=50, line=dict(color='yellow', dash='dash'))\n",
    "g.add_shape(type='line', x0=50, y0=0, x1=50, y1=50, line=dict(color='yellow', dash='dash'))\n",
    "kw = {\n",
    "    'marker': dict(\n",
    "        size=(2*idx['Adj Close'].pct_change().iloc[x] / idx['Adj Close'].pct_change().std())**2+5,\n",
    "        line=dict(width=3, color=idx['RSI'].iloc[x], cmax=2, cmin=-2, colorscale=\"RdYlGn\")\n",
    "    ),\n",
    "    'textfont': dict(color=[f\"rgba(255, 255, 255, 0.{8 if t else 2})\" for t in trend.iloc[x]]),\n",
    "    'textposition': cloudposition,\n",
    "}\n",
    "g.update_traces(**kw) # hovertemplate=s+'=%{y}<extra></extra>'\n",
    "g.update_layout(xaxis_title=\"MACD Frequency\", yaxis_title=\"RSI Frequency\", showlegend=False)\n",
    "g.update_coloraxes(showscale=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44484686-382a-448f-8d1e-34110fb32744",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3198b98-b8b0-45a6-a5c5-52216896ba46",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx.index = idx_index # FIX index datatype\n",
    "df = idx[-252*2-rwindow:].copy()\n",
    "adj_prc = df['Adj Close'].pct_change(rwindow).mul(100)\n",
    "adj_prc.columns = pd.MultiIndex.from_product([['Adj_prc'], df['Adj Close'].columns])\n",
    "df = df.join(adj_prc)\n",
    "df = df[['MACD_prc', 'RSI_prc', 'Adj Close', 'Adj_prc', 'symbol', 'trend']].unstack().reset_index()\n",
    "df = df.pivot(index=['level_2', 'Ticker'], columns='level_0', values=0).reset_index().dropna()\n",
    "df['color'] = df['Adj_prc'].rank(pct=True).mul(20).round()-10\n",
    "df['size'] = df['Adj_prc'].abs().round()+5\n",
    "df['Adj Close'] = df['Adj Close'].round(2)\n",
    "df['MACD_prc'] = df['MACD_prc'].round(1)\n",
    "df['RSI_prc'] = df['RSI_prc'].round(1)\n",
    "if '^VIX' in idx['Adj Close'].columns:\n",
    "    df.loc[df['Ticker'] == '^VIX', 'Adj_prc'] = -df.loc[df['Ticker'] == '^VIX', 'Adj_prc']\n",
    "fig = px.scatter(df.dropna(), x='MACD_prc', y='RSI_prc', text='Ticker',\n",
    "     color='color', color_continuous_scale='RdYlGn', color_continuous_midpoint=0.0, range_color=[-10,10],\n",
    "    # opacity='trend',\n",
    "     symbol='symbol', symbol_map=symbol_map,\n",
    "     size=list(df['size']), size_max=100,\n",
    "     hover_data=['Adj Close'],\n",
    "     animation_frame='level_2', \n",
    "     animation_group='Ticker',\n",
    "     range_x=[0, 100], range_y=[0, 100],\n",
    "     title=\"Animated MACD vs RSI Rankings\",\n",
    "     template=template)\n",
    "fig.add_shape(type='line', x0=50, y0=50, x1=100, y1=50, line=dict(color='red', dash='dash'))\n",
    "fig.add_shape(type='line', x0=50, y0=50, x1=50, y1=100, line=dict(color='red', dash='dash'))\n",
    "fig.add_shape(type='line', x0=0, y0=50, x1=50, y1=50, line=dict(color='yellow', dash='dash'))\n",
    "fig.add_shape(type='line', x0=50, y0=0, x1=50, y1=50, line=dict(color='yellow', dash='dash'))\n",
    "fig.update_layout(\n",
    "    showlegend=False,\n",
    "    updatemenus=[dict(\n",
    "        type='buttons',\n",
    "        showactive=False,\n",
    "        buttons=[dict(\n",
    "            label='Play',\n",
    "            method='animate',\n",
    "            args=[None, dict(frame=dict(duration=300, redraw=True), fromcurrent=True)]\n",
    "        ), dict(\n",
    "            label='Pause',\n",
    "            method='animate',\n",
    "            args=[[None], dict(frame=dict(duration=0, redraw=True), mode='immediate')]\n",
    "        )]\n",
    "    )]\n",
    ")\n",
    "fig.update_coloraxes(showscale=False)\n",
    "#fig.frames = sorted(fig.frames, key=lambda f: f.name)\n",
    "# fig.layout[\"sliders\"][0][\"active\"] = len(fig.frames) - 1  # Set slider position to the last frame\n",
    "# fig.update_traces(fig.frames[-1].data[-1]) # ???\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dc4a4a-e300-4df6-9ca5-afa1620e9dc4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3e26bf-d7ae-46d2-8203-10a30d18361f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tickers = {n: Ticker(n) for n in summary.index}\n",
    "funds = {n: t.all_modules[n] for n, t in tickers.items()}\n",
    "holdings = {fund:funds[fund][\"topHoldings\"]['holdings'] for fund in funds if funds[fund].get('topHoldings')}\n",
    "recommendations = {n: t.recommendations for n, t in tickers.items()}\n",
    "insights = {n: t.technical_insights[n] for n, t in tickers.items()}\n",
    "\n",
    "types = []\n",
    "for fund in funds:\n",
    "    if funds[fund][\"quoteType\"]['quoteType'] in ['CRYPTOCURRENCY', 'INDEX']: # Crypto\n",
    "        types.append(funds[fund][\"quoteType\"]['quoteType'])\n",
    "    elif 'ETF' == funds[fund][\"quoteType\"]['quoteType']:\n",
    "        types.append(funds[fund][\"fundProfile\"]['categoryName'])\n",
    "    else: #'EQUITY' == funds[fund][\"quoteType\"]['quoteType'] = Stock\n",
    "        types.append(funds[fund][\"assetProfile\"]['sector'])\n",
    "summary['category'] = types\n",
    "summary['trailingPE'] = [funds[fund][\"summaryDetail\"].get('trailingPE',0) for fund in funds]\n",
    "summary = pd.concat((summary, ann_risk_return(prices.div(100))), axis=1)\n",
    "summary[\"Sharpe\"] = (summary[\"Return\"].sub(risk_free_return))/summary[\"Risk\"]\n",
    "summary[\"TotalRisk\"] = np.power(summary.Risk, 2)\n",
    "summary[\"SystRisk\"] = (prices.div(100).cov()*252).loc[:,'VOO' if 'VOO' in prices.columns else prices.columns[-1]]\n",
    "summary[\"UnsystRisk\"] = summary[\"TotalRisk\"].sub(summary[\"SystRisk\"])\n",
    "json_struct = json.loads(pd.DataFrame(insights).drop(['upsell', 'symbol'], errors='ignore').T.to_json(orient=\"records\"))\n",
    "df_flat = pd.json_normalize(json_struct)\n",
    "df_flat.drop([c for c in df_flat.columns if c.endswith(('indexScoreDescription', '.stateDescription', '.provider', '.indexDirection',\n",
    "        '.direction', '.score', '.indexScore', '.sectorDirection', 'sectorScore', 'sectorScoreDescription', 'sector',\n",
    "        'sigDevs', 'events', 'secReports', 'projectionValuesCat', 'reports', '.reportId', '.researchReports.title', 'companySnapshot'))],\n",
    "        axis=1, inplace=True)\n",
    "df_flat.drop([c for c in df_flat.columns if c.startswith(('companySnapshot', 'valuation'))],\n",
    "        axis=1, inplace=True)\n",
    "\n",
    "df_flat.columns= [c.replace('instrumentInfo.', '') for c in df_flat.columns]\n",
    "df_flat.columns= [c.replace('technicalEvents.', '') for c in df_flat.columns]\n",
    "df_flat.columns= [c.replace('keyTechnicals.', '') for c in df_flat.columns]\n",
    "df_flat.index = summary.index\n",
    "df_flat = df_flat.T\n",
    "df_flat = pd.concat((df_flat, pd.DataFrame(\n",
    "    {fund['quoteType']['symbol']:\n",
    "    {'annualReportExpenseRatio': fund.get('fundProfile',{}).get('feesExpensesInvestment',{}).get('annualReportExpenseRatio',0)}\n",
    "    for fund in funds.values()}\n",
    ")))\n",
    "display(HTML(\"<style>:root { --jp-notebook-max-width: 96% !important; }</style>\"))\n",
    "\n",
    "noa = len(prices.columns)\n",
    "np.random.seed(NOP)\n",
    "matrix = np.random.random(noa*NOP).reshape(NOP, noa)\n",
    "weights = matrix / matrix.sum(axis=1, keepdims=True)\n",
    "port_ret = prices.div(100).dot(weights.T)\n",
    "port_summary = ann_risk_return(port_ret)\n",
    "port_summary[\"Sharpe\"] = (port_summary[\"Return\"].sub(risk_free_return))/port_summary[\"Risk\"]\n",
    "port_summary[\"Sortino\"] = get_sortino(port_ret.iloc[:,:-1])\n",
    "msrp = port_summary.Sharpe.idxmax()\n",
    "msrp1 = port_summary.Sortino.idxmax()\n",
    "msrp_w = weights[msrp, :]\n",
    "msrp1_w = weights[msrp1, :]\n",
    "category = [get_parent(tick) for tick in list(prices.columns[:len(msrp_w)])]\n",
    "summary['category'] = category\n",
    "if len(prices.columns) == len(msrp_w):\n",
    "    prices['sharpe'] = (prices * msrp_w).sum(axis=1)\n",
    "if len(prices.columns) > len(msrp1_w):\n",
    "    msrp1_w = np.append(msrp1_w, 0)\n",
    "    prices['sortino'] = (prices * msrp1_w).sum(axis=1)\n",
    "summary['weight'] = msrp_w*100\n",
    "summary['weight1'] = msrp1_w[:summary.shape[0]]*100\n",
    "pole = \"VOO\" if \"VOO\" in prices.columns else prices.columns[0]\n",
    "summary[\"beta\"] = summary.SystRisk / summary.loc[pole, \"SystRisk\"]\n",
    "summary[\"capm_ret\"] = risk_free_return + (summary.loc[pole, \"Return\"] - risk_free_return) * summary.beta\n",
    "summary[\"alpha\"] = summary.Return - summary.capm_ret\n",
    "summary = pd.concat((summary, df_flat.iloc[:-5].T), axis=1) # Next, analysts outlook\n",
    "summary = pd.concat((summary, df_flat.iloc[-1].T*100), axis=1) # annual expense\n",
    "\n",
    "sortval = summary['MACD_prc'] * summary['RSI_prc']\n",
    "edf = {}\n",
    "for j, v in enumerate(sortval.sort_values(ascending=False).index):\n",
    "    edf[v] = idx.swaplevel(0, 1, axis=1)[v]\n",
    "    edf[v] = calc_ichimoku(edf[v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346e7121-8333-4e03-b073-42f0838fee85",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "weight = {}\n",
    "if os.path.exists('orders.json'):\n",
    "    with open('vanguard.json', 'r') as file:\n",
    "        data = json.load(file)\n",
    "    for account in data['data']['accountsInfo']['accounts']:\n",
    "        for p in account['positions']:\n",
    "            if not p.get('ticker') or p['ticker'] == 'VMFXX':\n",
    "                continue\n",
    "            weight[p['ticker']] = weight.get(p['ticker'], 0) + p['quantity'] #p['currentBalance']\n",
    "    total = sum([summary['Adj Close'][x] * weight.get(x, 0) for x in summary['Adj Close'].index])\n",
    "            \n",
    "    a=[]\n",
    "    for fund in funds:\n",
    "        if not fund in weight:\n",
    "            continue\n",
    "        hold_sum = 0\n",
    "        t = None\n",
    "        for t in funds[fund].get('topHoldings',{}).get('holdings',{}):\n",
    "            t['etf'] = fund\n",
    "            t['category'] = summary.loc[fund, 'category']\n",
    "            t['weight'] = int(weight.get(fund, 0.0) * summary.loc[fund]['Adj Close'] * t['holdingPercent']) # $ value of holding\n",
    "            t['prc'] = t['weight'] * 100 / total\n",
    "            hold_sum += t['holdingPercent']\n",
    "            t['Return'] = summary.loc[fund, 'Return'] #* 100\n",
    "            t['color'] = idx['RSI_prc',fund].iloc[-1]/25-2\n",
    "            a.append(t)\n",
    "        z={}\n",
    "        z['holdingName'] = '<other>'\n",
    "        z['etf'] = fund\n",
    "        z['category'] = summary.loc[fund, 'category']\n",
    "        z['weight'] = int(abs(weight.get(fund, 0) * summary.loc[fund, 'Adj Close'] * (1-(hold_sum if t else 0))))\n",
    "        z['prc'] = z['weight'] * 100 / total\n",
    "        z['Return'] = summary.loc[fund, 'Return'] #* 100\n",
    "        z['color'] =  idx['MACD_prc',fund].iloc[-1]/25-2\n",
    "        a.append(z)\n",
    "    \n",
    "    tree = pd.DataFrame(a)\n",
    "    tree = tree[tree['prc']>0.005]\n",
    "    fig = px.treemap(tree, title=f\"Portfolio Structure\", path=['category', 'etf', 'holdingName'], values='weight', #labels=\"parent\",\n",
    "             hover_name='etf', hover_data=['prc', 'holdingPercent', 'Return', 'color'],\n",
    "             color_continuous_midpoint=0, color_continuous_scale=\"Temps\", color='color', range_color=(-2,2))\n",
    "    fig.update_layout(margin=dict(l=10, r=10, b=10, t=30), template=template, coloraxis_showscale=False)\n",
    "    fig.update_traces(marker=dict(cornerradius=5))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd4c48d-2924-4a6b-83e7-8be467db96f3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Sharpe/ Sortino Portfolio Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6d04b5-889a-4de4-98c6-58cf089f9de1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "a=[]\n",
    "for fund in funds:\n",
    "    hold_sum = 0\n",
    "    t = None\n",
    "    for t in funds[fund].get('topHoldings',{}).get('holdings',{}):\n",
    "        t['etf'] = fund\n",
    "        t['category'] = summary.loc[fund, 'category']\n",
    "        t['weight']=summary.loc[fund, 'weight' if model=='Sharpe' else 'weight1']\n",
    "        t['holding'] = t['weight'] * t['holdingPercent']\n",
    "        hold_sum += t['holdingPercent']\n",
    "        t['Return'] = summary.loc[fund, 'Return'] #* 100\n",
    "        t['color'] = idx['RSI_prc',fund].iloc[-1]/25-2\n",
    "        a.append(t)\n",
    "    z={}\n",
    "    z['holdingName'] = '<other>'\n",
    "    z['etf'] = fund\n",
    "    z['category'] = summary.loc[fund, 'category']\n",
    "    z['weight']=summary.loc[fund, 'weight' if model=='Sharpe' else 'weight1']\n",
    "    z['holding'] = abs(t['weight'] * (1-hold_sum)) if t else 1\n",
    "    z['Return'] = summary.loc[fund, 'Return'] #* 100\n",
    "    z['color'] =  idx['MACD_prc',fund].iloc[-1]/25-2\n",
    "    a.append(z)\n",
    "\n",
    "tree = pd.DataFrame(a)\n",
    "fig = px.treemap(tree, title=f\"{model} Portfolio Structure\", path=['category', 'etf', 'holdingName'], values='holding', #labels=\"parent\",\n",
    "         hover_name='etf',\n",
    "         hover_data=['Return', 'color'],\n",
    "         color_continuous_midpoint=0, color_continuous_scale=\"Temps\", color='color', range_color=(-2,2))\n",
    "fig.update_layout(margin=dict(l=10, r=10, b=10, t=30), template=template, coloraxis_showscale=False)\n",
    "fig.update_traces(marker=dict(cornerradius=5))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86f6bc0-aed5-49f1-a058-9d98d0704df8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Buy/ Sell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943d6dd9-54bc-4ce3-b960-d312e1ba8601",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: line charts overlays against VOO\n",
    "def alpha_arbitrage(v, msk):\n",
    "    d = 22\n",
    "    df = (edf[v]['Adj Close'].pct_change(-d, fill_method=None)*100).to_frame(name=\"a_\")\n",
    "    df[\"r_\"] = (edf[v]['Adj Close'].pct_change(-d, fill_method=None) - idx['Adj Close','VOO'].pct_change(-d, fill_method=None))*100\n",
    "    df['ticker'] = v\n",
    "    for t in [22, 44, 66, 88]:\n",
    "        df[f\"r{t}\"] = idx['Adj Close'][v].pct_change(t, fill_method=None) * 100\n",
    "        df[f\"r{t}\"] = df[f\"r{t}\"]-(idx['Adj Close','VOO'].pct_change(t, fill_method=None)*100)\n",
    "    return df[msk][['r22', 'r44', 'r66', 'r88']].mean().mean()\n",
    "\n",
    "def spread_mask(msk, n=3):\n",
    "    msk = (msk - msk.shift(1)) == 1 # Break contiguous\n",
    "    for i in range(n):\n",
    "        msk = msk & (1-msk.shift(i+1))\n",
    "    return msk\n",
    "\n",
    "def get_msk_buy(v):\n",
    "    # Anomalous RSI/ MACD\n",
    "    msk = (edf[v]['RSI_prc'].rank(pct=True)*100 < cutoff/cofactor) | (edf[v]['MACD_prc'].rank(pct=True)*100 < cutoff/cofactor)\n",
    "    # Bollinger Bands\n",
    "    msk = ((edf[v]['LBAND'] < edf[v]['Adj Close']) & (edf[v]['LBAND'].shift(1) > edf[v]['Adj Close'].shift(1))) | msk\n",
    "    # Add momentum\n",
    "    # msk = (edf[v]['MACD'].rolling(rwindow).mean().rank(pct=True) < .30) & (edf[v]['MACD'].rank(pct=True) > 0.20) | msk\n",
    "    \n",
    "    msk = (\n",
    "        (edf[v]['Adj Close'] < edf[v]['Adj Close'].shift(22) * .948) & # Drop from a month ago\n",
    "        (edf[v]['RSI_prc'] - edf[v]['MACD_prc'] < 0.66) & # Started climbing from bottom up\n",
    "        (edf[v]['RSI_prc'].rolling(5).min().rank(pct=True) < .4) # Makes it skip shallow minimums\n",
    "    ) | msk\n",
    "    \n",
    "    # msk = msk & (1-msk.rolling(4).min()).shift(-1)\n",
    "    return spread_mask(msk, n=3)\n",
    "\n",
    "def get_msk_sell(v):\n",
    "    # Anomalous RSI/ MACD\n",
    "    msk = ((edf[v]['RSI_prc'].rank(pct=True)*100 > 100-cutoff/cofactor) | (edf[v]['MACD_prc'].rank(pct=True)*100 > 100-cutoff/cofactor))\n",
    "    # Bollinger Bands\n",
    "    msk = ((edf[v]['UBAND'] > edf[v]['Adj Close']) & (edf[v]['UBAND'].shift(1) > edf[v]['Adj Close'].shift(1))) | msk\n",
    "    # Add momentum\n",
    "    # msk = ((edf[v]['RSI'] > 0) & ((edf[v]['RSI_prc']-edf[v]['MACD_prc']) > cutoff)) | msk\n",
    "    # msk = (edf[v]['MACD'].rolling(rwindow).mean().rank(pct=True) > .70) & (edf[v]['MACD'].rank(pct=True) < .60) #| msk\n",
    "    # msk = msk & (1-msk.rolling(4).max()).shift(-1)\n",
    "    return spread_mask(msk, n=3)\n",
    "\n",
    "# display(alpha_arbitrage(v, msk))\n",
    "alpha = [(alpha_arbitrage(v, get_msk_buy(v))) for v in summary.index if v!='^VIX']\n",
    "display(sum(alpha)/len(alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c025f8-6a26-423a-987a-c4239373b2ab",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "last_buy, last_sell, last_na, last_delta, last_buy_price, last_sell_price, signal = [], [], [], [], [], [], []\n",
    "for v in summary.index:\n",
    "    # Sell\n",
    "    msk_s = get_msk_sell(v) # arbitrage_returns.update(alpha_arbitrage(v, msk))\n",
    "    # Buy\n",
    "    msk_b = get_msk_buy(v)\n",
    "    msk_b, msk_s = msk_b & (1 - msk_s), msk_s & (1 - msk_b)\n",
    "    \n",
    "    day_b, day_s = msk_b[msk_b==True].tail(1).index, msk_s[msk_s==True].tail(1).index\n",
    "    \n",
    "    if msk_b.iloc[idx['Adj Close'][v].size-1]:\n",
    "        signal.append('Buy')\n",
    "    elif msk_s.iloc[idx['Adj Close'][v].size-1]:\n",
    "        signal.append('Sell')\n",
    "    else:\n",
    "        signal.append('')\n",
    "\n",
    "    last_buy.append(day_b)\n",
    "    last_sell.append(day_s)\n",
    "    last_buy_price.append(idx.loc[day_b, ('Adj Close', v)].values[0])\n",
    "    last_sell_price.append(idx.loc[day_s, ('Adj Close', v)].values[0])\n",
    "    last_delta.append(\n",
    "        (\n",
    "            100 * (last_sell_price[-1] - last_buy_price[-1]) / last_buy_price[-1]\n",
    "        ) if day_s < day_b else (\n",
    "            100 * (last_buy_price[-1] - last_sell_price[-1]) / last_sell_price[-1]\n",
    "        )\n",
    "    )\n",
    "summary['last_buy'] = last_buy\n",
    "summary['last_sell'] = last_sell\n",
    "summary['last_buy_price'] = last_buy_price\n",
    "summary['last_sell_price'] = last_sell_price\n",
    "for b, s in zip(last_buy, last_sell):\n",
    "    last_na.append((b-s).to_series().dt.days.values[0])\n",
    "summary['last_na'] = last_na\n",
    "summary['last_delta'] = last_delta\n",
    "summary['signal'] = signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777cf94c-93f1-4a57-8e52-1200ea811c8d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: animate reverse chronology\n",
    "indicators = summary.copy()\n",
    "indicators.drop(['^VIX'], inplace=True, errors='ignore')\n",
    "lb = indicators['last_buy'] - pd.Timestamp(idx.index[-1]).date()\n",
    "ls = indicators['last_sell'] - pd.Timestamp(idx.index[-1]).date()\n",
    "indicators['last_buy'] = [lb[s][0].days for s in indicators.index]\n",
    "indicators['last_sell'] = [ls[s][0].days for s in indicators.index]\n",
    "color_map = {\"Sell\": \"red\", \"Buy\": \"green\", \"\": \"black\"}\n",
    "layout = dict(\n",
    "    title=f\"Last transaction\",\n",
    "    hover_data=['last_buy_price', 'last_sell_price', 'last_buy', 'last_sell'],\n",
    "    hover_name = indicators.index,\n",
    "    text=[\"\" if lb[s][0].days and ls[s][0].days else s for s in indicators.index],\n",
    "    x='last_na',\n",
    "    y='last_delta',\n",
    "    color = 'signal',\n",
    "    template=template # color=summary[\"last_buy\"], # color_continuous_scale='RdYlGn', color_continuous_midpoint=0.0,\n",
    ")\n",
    "g = px.scatter(indicators, **layout)\n",
    "g.update_traces(textfont=dict(size=12), textposition=\"top center\", showlegend=False)\n",
    "for i, trace in enumerate(g.data):\n",
    "    trace.textfont.color = color_map[trace.name]  # Assign the category color to the text\n",
    "g.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c88774-f234-440f-8eca-8351d9f4134e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a042f8d1-155e-4c63-919d-c523b1b89f61",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: eval % of time price between buys stays above green line\n",
    "# TODO: self tune to max 10 buy signals\n",
    "titles = []\n",
    "sortval = (summary['MACD_prc'] * summary['RSI_prc'])**.5 # Beaten up first\n",
    "for title in sortval.sort_values(ascending=True).index:\n",
    "    titles.extend([\"{} {:.1f}%\".format(title, sortval.loc[title]), None])\n",
    "kw = dict(\n",
    "    rows=2*summary['MACD_prc'].size,\n",
    "    cols=1,\n",
    "    shared_xaxes=True,\n",
    "    vertical_spacing=.01,\n",
    "    horizontal_spacing=.01,\n",
    "    row_heights=[600, 200] * summary['MACD_prc'].size,\n",
    "    subplot_titles=titles\n",
    ")\n",
    "fig = make_subplots(**kw)\n",
    "for j, v in enumerate(sortval.sort_values(ascending=True).index):\n",
    "    kwtop={\"row\":1+2*j, \"col\":1}\n",
    "    kwbottom={\"row\":2+2*j, \"col\":1}\n",
    "\n",
    "    # bollinger bands\n",
    "    g = px.line(edf[v], x=edf[v].index, y='Adj Close')\n",
    "    g.update_traces(line_color='blue', hovertemplate='%{y:.2f}<extra></extra>')\n",
    "    fig.add_trace(g.data[0], **kwtop)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=pd.concat([pd.DataFrame(edf[v]['UBAND'].dropna()), pd.DataFrame(edf[v]['LBAND'].dropna())[::-1]]).index,\n",
    "        y=pd.concat([edf[v]['UBAND'].dropna(), edf[v]['LBAND'].dropna()[::-1]]),\n",
    "        fill='toself',\n",
    "        fillcolor='rgba(64, 64, 64, 0.35)',  # Semi-transparent green\n",
    "        line=dict(color='rgba(255, 255, 255, 0)'),  # Invisible line\n",
    "        name='Bollinger Bands Area',\n",
    "        showlegend=False,\n",
    "        hovertemplate=\"\"\n",
    "    ), **kwtop)\n",
    "\n",
    "    # Sell\n",
    "    msk_s = get_msk_sell(v) # arbitrage_returns.update(alpha_arbitrage(v, msk))\n",
    "    # Buy\n",
    "    msk_b = get_msk_buy(v)\n",
    "    msk_b, msk_s = msk_b & (1 - msk_s), msk_s & (1 - msk_b)\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=edf[v][msk_b].index, y=edf[v][msk_b]['Adj Close'], name='Buy', showlegend=False, line=dict(color='rgba(0, 255, 0, 0.6)', width=1),\n",
    "    ), **kwtop)\n",
    "    if v!='^VIX':\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=edf[v][msk_s].index, y=edf[v][msk_s]['Adj Close'], name='Sell', showlegend=False, line=dict(color='rgba(255, 0, 0, 0.6)', width=1),\n",
    "        ), **kwtop)\n",
    "\n",
    "    ### ICHIMOKU CLOUD ###\n",
    "    kwich={'x': edf[v].index, 'type': 'scatter', 'mode': 'lines', 'showlegend': False, 'hovertemplate': \"\"}\n",
    "    fig.add_trace(go.Scatter(\n",
    "        y=np.where(edf[v]['senkou_span_a'] > edf[v]['senkou_span_b'], edf[v]['senkou_span_a'], edf[v]['senkou_span_b']),\n",
    "        name='senkou_span_max',\n",
    "        line=dict(width=0),\n",
    "        **kwich), **kwtop)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        y=edf[v]['senkou_span_b'], \n",
    "        fill='tonexty',\n",
    "        fillcolor='rgba(0, 128, 0, 0.25)',\n",
    "        line=dict(color='rgba(0, 128, 0, 0.1)'),\n",
    "        name='senkou_span_a above',\n",
    "        **kwich), **kwtop)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        y=np.where(edf[v]['senkou_span_b'] > edf[v]['senkou_span_a'], edf[v]['senkou_span_b'], edf[v]['senkou_span_a']),\n",
    "        name='senkou_span_min',\n",
    "        line=dict(width=0),\n",
    "        **kwich), **kwtop)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        y=edf[v]['senkou_span_a'], \n",
    "        fill='tonexty',\n",
    "        fillcolor='rgba(128, 0, 0, 0.25)',\n",
    "        line=dict(color='rgba(128, 0, 0, 0.1)'),\n",
    "        name='senkou_span_b above',\n",
    "        **kwich), **kwtop)\n",
    "\n",
    "    # RSI\n",
    "    g = px.line(edf[v], x=edf[v].index, y=edf[v]['RSI'].rolling(rwindow).mean().rank(pct=True)*2-1)\n",
    "    g.update_traces(hovertemplate='RSI=%{y:.2f}<extra></extra>', line={'width': 1, 'color': 'orange'})\n",
    "    fig.add_trace(g.data[0], **kwbottom)\n",
    "    # Convergence/ divergence\n",
    "    g = px.bar(edf[v], x=edf[v].index, y=edf[v]['MACD'].rolling(rwindow).mean().rank(pct=True)*2-1)\n",
    "    g.update_traces(marker_color=np.where(edf[v]['MACD'] > 0, 'red', 'green'), hovertemplate='MACD=%{y:.2f}<extra></extra>')\n",
    "    \n",
    "    fig.add_trace(g.data[0], **kwbottom)\n",
    "    fig.update_yaxes(type=\"log\", **kwtop)\n",
    "    fig.update_yaxes(**kwbottom)\n",
    "    fig.update_xaxes(range=[edf[v].index[ichimoku_window*2], edf[v].index[-1]], **kwtop)\n",
    "    fig.update_xaxes(range=[edf[v].index[ichimoku_window*2], edf[v].index[-1]], **kwbottom)\n",
    "\n",
    "kw = dict(\n",
    "    margin=dict(l=10, r=10, b=10, t=10),\n",
    "    template=template,\n",
    "    height=800*j,\n",
    "    hovermode='x unified',\n",
    "    legend_traceorder=\"normal\",\n",
    "    spikedistance=5,\n",
    "    xaxis=dict(spikecolor=\"white\",\n",
    "       spikethickness=.25,\n",
    "       spikedash='dash',\n",
    "       spikemode='toaxis+across+marker',\n",
    "    ),\n",
    "    autosize=True,\n",
    ")\n",
    "fig.update_layout(**kw)\n",
    "fig.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa46bf0a-73d6-41c9-888a-f09a50aa0707",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ff4d1a-10d7-45e4-9072-2d0fdf0e08c5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# summary['signal_bollinger'] = np.where((idx['Adj Close'] < idx['LBAND']).iloc[-1].values, 'Buy', \n",
    "#                     np.where((idx['Adj Close'] > idx['UBAND']).iloc[-1].values, 'Sell', ''))\n",
    "# summary['signal_rsi'] = np.where((idx['RSI_prc'].rank(pct=True)*100 < cutoff/cofactor) | (idx['MACD_prc'].rank(pct=True)*100 < cutoff/cofactor), 'Buy', \n",
    "#                     np.where((idx['RSI_prc'].rank(pct=True)*100 > 100-cutoff/cofactor) | (idx['MACD_prc'].rank(pct=True)*100 > 100-cutoff/cofactor), 'Sell', ''))[-1]\n",
    "\n",
    "summary['url'] = summary.index\n",
    "summary[\"url\"] = summary.apply(lambda row: \"<a href='https://www.etfdb.com/etf/{}/#holdings' target='_blank'>{}</a>\".format(row.url, row.url), axis=1)\n",
    "summary = summary.loc[:, ~summary.columns.str.startswith(\"last_\")]\n",
    "display(HTML(summary.drop(['^VIX'], errors='ignore').infer_objects(copy=False).fillna('').T.style.apply(h_bull, axis=1).apply(h_bear, axis=1).apply(h_min, axis=1).apply(h_max, axis=1).to_html(escape=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62f8fe5-d646-4af3-abd3-ab1f3e39e9b2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "indicators = summary[['Adj Close', 'LBAND']].copy()\n",
    "indicators['macd'] = [de_macd(fund) for fund in summary.index]\n",
    "indicators['rsi'] = [de_rsi(fund) for fund in summary.index]\n",
    "for i in range(1,4):\n",
    "    if i > 1:\n",
    "        indicators[f\"std{i}\"] = indicators[f\"std{i-1}\"] * (1-((idx['Adj Close'].std()**.5)/idx['Adj Close'].iloc[-1]))\n",
    "    else:\n",
    "        indicators[f\"std{i}\"] = idx['Adj Close'].iloc[-1] - i * idx['Adj Close'].std()**.5\n",
    "\n",
    "def get_expiry(row):\n",
    "    if row['duration_type'] == 'DAY':\n",
    "        # Assume expires end of trade date (23:59:59)\n",
    "        return row['trade_dt'].normalize() + pd.Timedelta(days=1) - pd.Timedelta(seconds=1)\n",
    "    elif row['duration_type'] == 'SIXTY_DAY':\n",
    "        return pd.to_datetime(row['duration'].get('goodTillDate'))\n",
    "    else:\n",
    "        return pd.NaT  # fallback for unknown duration types\n",
    "\n",
    "if os.path.exists('orders.json'):\n",
    "    with open('orders.json', 'r') as file:\n",
    "        data = json.load(file)\n",
    "    orders = pd.DataFrame(data['data']['orderActivity'])\n",
    "    # Check expirations\n",
    "    orders['trade_dt'] = orders['tradeDate'].apply(lambda x: pd.to_datetime(x['date']))\n",
    "    orders['duration_type'] = orders['duration'].apply(lambda x: x['type'])\n",
    "    # Compute expiry datetime\n",
    "    orders['expiry_dt'] = orders.apply(get_expiry, axis=1)\n",
    "    # Determine if expired\n",
    "    now = pd.Timestamp.now()\n",
    "    orders['is_expired'] = orders['expiry_dt'] < now\n",
    "    orders = orders[~orders['is_expired']]\n",
    "    \n",
    "    orders = orders[(orders['status'] == 'OPEN') | (orders['status'] == 'ENTERED')]\n",
    "    orders['ticker'] = orders['description'].apply(lambda x: x.get('ticker'))\n",
    "    orders['limit'] = orders['stopLimitPrice'].apply(lambda x: x.get('limit'))\n",
    "    # orders = orders[['orderId', 'accountId','askPrice','requestedAmount','ticker','limit']]\n",
    "    orders = orders.set_index('orderId')\n",
    "    grouped = orders.groupby('ticker')\n",
    "    indicators['limit'] = indicators.index.map(grouped['limit'].max())\n",
    "    # indicators['askPrice'] = indicators.index.map(grouped['askPrice'].max())\n",
    "indicators.drop(['^VIX'], inplace=True, errors='ignore')\n",
    "fig = px.imshow((indicators['Adj Close'].T-indicators.T)/indicators.T.std(), template=template, title='Buy Indicators', color_continuous_scale=[\"blue\", 'white', \"red\"], range_color=[-3, 3], color_continuous_midpoint=0, text_auto=False)\n",
    "text_abs = [[indicators[c].values] for c in indicators.columns]\n",
    "# text_prc = [[(indicators[c].values/ indicators['Adj Close'].values)*100-100 ] for c in indicators.columns]\n",
    "text_prc = [[[None] * len(indicators.index) if indicators[c].isnull().all() else (indicators[c].values/ indicators['Adj Close'].values)*100-100] for c in indicators.columns]\n",
    "# text_prc = [[[100] * len(indicators.index) if indicators[c].isnull().all() else indicators[c].values] for c in indicators.columns]\n",
    "custom_text=[]\n",
    "for row1, row2 in zip(text_abs, text_prc):\n",
    "    for j in range(len(row2)):\n",
    "        c_t = []\n",
    "        for k in range(len(row2[j])):\n",
    "            if not row1[j][k]:\n",
    "                c_t.append(\"\")\n",
    "                continue\n",
    "            if row1[j][k] < text_abs[-1][0][k] - .01:\n",
    "                c_t.append(\"^<br>{:.2f}<br>{:.1f}%\".format(row1[j][k], row2[j][k]))\n",
    "            else:\n",
    "                c_t.append(\"{:.2f}<br>{:.1f}%\".format(row1[j][k], row2[j][k]))\n",
    "        custom_text.append(c_t)\n",
    "\n",
    "fig.update_traces(text=custom_text, texttemplate=\"%{text}\")\n",
    "fig.update_layout(xaxis=dict(side=\"top\"), font=dict(size=16), coloraxis_showscale=False)\n",
    "\n",
    "border_color = \"green\"\n",
    "border_width = 2\n",
    "for i, v in enumerate([lb[s][0].days for s in indicators.index]):\n",
    "    if v:\n",
    "        continue\n",
    "    fig.add_shape(type=\"rect\",\n",
    "                  x0=i - 0.5, y0= - 0.5,\n",
    "                  x1=i + 0.5, y1= 0.5,\n",
    "                  line=dict(color=border_color, width=border_width),\n",
    "                  fillcolor=\"rgba(0,0,0,0)\")  # Transparent fill\n",
    "\n",
    "border_color = \"red\"\n",
    "border_width = 2\n",
    "for i, v in enumerate([ls[s][0].days for s in indicators.index]):\n",
    "    if v:\n",
    "        continue\n",
    "    fig.add_shape(type=\"rect\",\n",
    "                  x0=i - 0.5, y0= - 0.5,\n",
    "                  x1=i + 0.5, y1= 0.5,\n",
    "                  line=dict(color=border_color, width=border_width),\n",
    "                  fillcolor=\"rgba(0,0,0,0)\")  # Transparent fill\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d3dc1d-5b1e-4faa-9696-2b92585bb140",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Comparisons ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee341264-2b6c-41bd-90c6-124d54b6e58b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Ichimoku ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5872140-b277-4776-a805-38af7b72c8ed",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "howmany = 9\n",
    "x_values = sortval.sort_values(ascending=True).index[:howmany]\n",
    "fig = make_subplots(rows=howmany, cols=1, subplot_titles=[f'{x}' for x in x_values], shared_xaxes=True)\n",
    "for i, x_value in enumerate(x_values):\n",
    "    single_fig = plot2_ichimoku(d=edf[x_value], ticker_name=x_value)\n",
    "    for trace in single_fig.data:\n",
    "        fig.add_trace(trace, col=1, row=i+1)\n",
    "    fig.update_layout(xaxis={'rangeslider': {'visible': False}, 'title': {'text': 'Date'}})\n",
    "    fig.update_layout(xaxis2={'rangeslider': {'visible': False}, 'title': {'text': 'Date'}})\n",
    "    fig.update_layout(xaxis3={'rangeslider': {'visible': False}, 'title': {'text': 'Date'}})\n",
    "    fig.update_layout(xaxis4={'rangeslider': {'visible': False}, 'title': {'text': 'Date'}})\n",
    "    fig.update_layout(xaxis5={'rangeslider': {'visible': False}, 'title': {'text': 'Date'}})\n",
    "    fig.update_layout(xaxis6={'rangeslider': {'visible': False}, 'title': {'text': 'Date'}})\n",
    "    fig.update_layout(xaxis7={'rangeslider': {'visible': False}, 'title': {'text': 'Date'}})\n",
    "    fig.update_layout(xaxis8={'rangeslider': {'visible': False}, 'title': {'text': 'Date'}})\n",
    "    fig.update_layout(xaxis9={'rangeslider': {'visible': False}, 'title': {'text': 'Date'}})\n",
    "    \n",
    "fig.update_layout(template=template, height=400*min(howmany, len(x_values)))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c3bead-e75e-4cb4-b066-e9b5e7249a94",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Comps ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d452b2d-6a71-45d6-a886-d06c9a1e3f20",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Today's liquidation\n",
    "s0 = 0\n",
    "for v in range(100):\n",
    "    ploc = int(v*(prices.shape[0]/100))\n",
    "    df = (prices/prices.iloc[ploc]).dropna()\n",
    "    df['Sharpe'], df['Sortino'] = (df.iloc[:,:len(msrp_w)] * msrp_w).sum(axis=1), (df.iloc[:,:len(msrp1_w)] * msrp1_w).sum(axis=1)\n",
    "    ratios = (ann_risk_return(df.iloc[ploc:,-2:])['Return']*100)[-2:].values\n",
    "    s0 = s0 + 1 if ratios[0] > ratios[1] else s0 -1\n",
    "model = 'Sharpe' if s0 > 0 else 'Sortino'\n",
    "print(f\"{abs(s0)}% of samples in favor of {model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd917d8-c177-46a5-9a50-691d1c9200da",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Range of liquidations, start prices\n",
    "s0 = 0\n",
    "for v in range(99, 0, -1):\n",
    "    ploc = int(v * (prices.shape[0] / 100))\n",
    "    if ploc < 2:\n",
    "        continue\n",
    "    df = (prices / prices.iloc[0]).dropna()\n",
    "    df['Sharpe'], df['Sortino'] = (df.iloc[:,:len(msrp_w)] * msrp_w).sum(axis=1), (df.iloc[:,:len(msrp1_w)] * msrp1_w).sum(axis=1)\n",
    "    ratios = (ann_risk_return(df.iloc[:ploc,-2:])['Return']*100)[-2:].values\n",
    "    s0 = s0 + 1 if ratios[0] > ratios[1] else s0 -1\n",
    "model = 'Sharpe' if s0 > 0 else 'Sortino'\n",
    "print(f\"{abs(s0)}% of samples in favor of {model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a631b4-8670-434c-b55d-4fb3892e9e4a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "v=0\n",
    "log=True\n",
    "df = (prices/prices.iloc[int(v*(prices.shape[0]/100))]).dropna()\n",
    "ar = ann_risk_return(df.iloc[int(v*(prices.shape[0]/100)):])\n",
    "layout = dict(\n",
    "    title=\"Normalized Returns since {}. Sharpe: {:.1f}%. Sortino: {:.1f}%. Max: {:.1f} ({})\".format(\n",
    "        str(prices.iloc[int(v*(prices.shape[0]/100))].name)[:10],\n",
    "        ar.iloc[-2]['Return']*100,\n",
    "        ar.iloc[-1]['Return']*100,\n",
    "        ar.Return.iloc[ar.Return.argmax()]*100,\n",
    "        ar.iloc[ar.Return.argmax()].name\n",
    "    ),\n",
    "    log_y=True,\n",
    "    template=template\n",
    ")\n",
    "px.line(df, **layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c99ee7c-8173-44f6-b810-9056772c2a61",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sector coverage in funds\n",
    "for i in range(summary.shape[0]):\n",
    "    try: # fund_sector_weightings fails for certain funds, need to find one that succeeds\n",
    "        if not any(tickers[summary.index[i]].fund_sector_weightings):\n",
    "            continue\n",
    "    except:\n",
    "        continue\n",
    "    break\n",
    "snames = tickers[summary.index[i]].fund_sector_weightings.index\n",
    "sectors=pd.DataFrame([\n",
    "    funds[fund][\"topHoldings\"]['sectorWeightings'] if funds[fund].get(\"topHoldings\",{}).get('sectorWeightings') else len(snames) * [None]\n",
    "    for fund in funds\n",
    "], index=summary.index, columns=snames).replace(to_replace=[None], value=[dict({'none': 0.0})])\n",
    "for c in sectors.columns:\n",
    "    sectors[c] = [v for d in sectors[c].values for v in d.values()]\n",
    "sectors = sectors.T\n",
    "sectors['sharpe']=(sectors * msrp_w).sum(axis=1)\n",
    "sectors['sortino']=(sectors * msrp1_w).sum(axis=1)\n",
    "\n",
    "\n",
    "### FIXME:\n",
    "if 'total' in locals():\n",
    "    port_w = [weight.get(f, 0) * summary.loc[f, 'Adj Close']/ total for f in funds] + [0, 0]\n",
    "    sectors['portfolio'] = (sectors * port_w).sum(axis=1)\n",
    "###\n",
    "\n",
    "sectors.sort_index(inplace=True)\n",
    "fig = px.imshow(sectors*100, template=template, title='Top Sectors')\n",
    "fig.update_layout(coloraxis_showscale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee438d45-1191-4b7f-a277-dfd19487359b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=1, cols=2, subplot_titles=(\"Price Correlation\", \"% Change Correlation\"))#, \"Price Covariance\"))\n",
    "kw = {\n",
    "    'x':prices.columns,\n",
    "    'y':prices.columns,\n",
    "    'colorscale': \"Jet\",\n",
    "    'showscale':False,\n",
    "}\n",
    "f1 = go.Heatmap(name='Correlation', z=prices.corr(), zmid=0.0, **kw)\n",
    "f2 = go.Heatmap(name='% Changes Correlation', z=prices.pct_change().corr(), zmid=0.0, **kw)\n",
    "\n",
    "fig.add_trace(f1, row=1, col=1)\n",
    "fig.add_trace(f2, row=1, col=2)\n",
    "fig.update_layout(template=template, height=500, width=1000, margin=dict(l=10, r=10, b=10, t=20))\n",
    "fig.update_yaxes(autorange=\"reversed\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374919f8-cc75-4600-99f1-d2522d163f51",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Lowest price change correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79fd07c-84c6-4c30-b75d-c7b235dc7e1f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "correlation_matrix = prices.drop(['^VIX'], axis=1, errors='ignore').pct_change().corr()\n",
    "corr_matrix = correlation_matrix.copy()\n",
    "np.fill_diagonal(corr_matrix.values, np.nan)\n",
    "correlations = corr_matrix.stack()\n",
    "# Filter to keep only one direction (A < B alphabetically)\n",
    "deduped = correlations[correlations.index.get_level_values(0) < correlations.index.get_level_values(1)]\n",
    "top_n = deduped.sort_values(ascending=False)\n",
    "top_n.tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94f5249-540e-4330-a33c-2452bbb89efc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(x=summary.index, y=summary['SystRisk'], name='SystRisk'))\n",
    "fig.add_trace(go.Bar(x=summary.index, y=summary['UnsystRisk'], name='UnsystRisk'))\n",
    "fig.update_layout({\n",
    "    # 'barmode': 'stack',\n",
    "    'title': \"Risks\",\n",
    "    'template': template,\n",
    "    'yaxis': {'title_text': \"Risk\"}\n",
    "})\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67a153c-5ad9-4e91-b4ff-e6a574f9e3d4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Obsolote"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4e484b65-2ea4-47f6-a64c-9506e2484a64",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Price correlation\n",
    "def reg_coef(x, y, label=None, color=None, cmap=None, **kwargs):\n",
    "    ax = plt.gca()\n",
    "    r, _ = stats.pearsonr(x, y)\n",
    "    norm = plt.Normalize(-1, 1)\n",
    "    cmap = cmap if not cmap is None else plt.cm.coolwarm\n",
    "    ax.annotate(f\"{r:.2f}\", xy=(0.5, 0.5), xycoords='axes fraction', ha='center', fontsize=16, bbox={'facecolor': cmap(norm(r)), 'alpha': r**4})\n",
    "    ax.set_axis_off()\n",
    "\n",
    "return_fig = sns.PairGrid(prices)\n",
    "# Using map_upper we can specify what the upper triangle will look like.\n",
    "return_fig.map_upper(plt.scatter, color='purple')\n",
    "return_fig.map_upper(reg_coef, cmap=plt.get_cmap('PiYG'))\n",
    "\n",
    "# We can also define the lower triangle in the figure, inclufing the plot type (kde) or the color map (BluePurple)\n",
    "return_fig.map_lower(sns.kdeplot, cmap='cool_d')\n",
    "# Finally we'll define the diagonal as a series of histogram plots of the daily return\n",
    "return_fig.fig.suptitle('Price Correlation', fontsize=24)\n",
    "return_fig.map_diag(plt.hist, bins=24);"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4be6beac-ccb1-40a6-9916-e506071f0549",
   "metadata": {},
   "source": [
    "slider = widgets.IntSlider(min=1, value=42) # 60 calendar days\n",
    "def print_val(v):\n",
    "    print(f\"Trading days: {v} {adj_prices.rolling(v).min().iloc[-1,:]}\")\n",
    "    return (prices.pct_change(v)*100).iplot(title=f\"Sliding Returns over {v} days\", theme='solar')\n",
    "interact(print_val,v=slider);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c4b967-5152-45c1-8ad9-84f9f7432e28",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Ratios ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ff1198-88c0-43bc-87a6-6246ae1a0206",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "options = ['alpha', 'beta', 'Risk', 'SystRisk', 'UnsystRisk', 'TotalRisk', 'Sharpe', 'capm_ret']\n",
    "slider = widgets.IntSlider(min=1, max=len(options))\n",
    "def print_val(v):\n",
    "    titles = (f\"Sharpe Portfolio Components Return vs {options[v-1]}: {port_summary.loc[msrp].Return*100:.1f}% {start.strftime('%Y')}-{end[:4]}\",\n",
    "            f\"Sortino Portfolio Components Return vs {options[v-1]}: {port_summary.loc[msrp1].Return*100:.1f}% {start.strftime('%Y')}-{end[:4]}\")\n",
    "    fig = make_subplots(rows=2, cols=1, shared_xaxes=True, shared_yaxes=True, subplot_titles=titles)\n",
    "    kw = {\n",
    "        'hovertext': summary.index,\n",
    "        'x':summary[options[v-1]],\n",
    "        'y':summary['Return'],\n",
    "        'mode':'markers',\n",
    "        'marker':dict(size=summary['weight']+1, color=pd.factorize(summary['category'])[0]),\n",
    "        'showlegend': False,\n",
    "    }\n",
    "    kw1 = {\n",
    "        'hovertext': summary.index,\n",
    "        'x':summary[options[v-1]],\n",
    "        'y':summary['Return'],\n",
    "        'mode':'markers',\n",
    "        'marker':dict(size=summary['weight1']+1, color=pd.factorize(summary['category'])[0]),\n",
    "        'showlegend': False,\n",
    "    }\n",
    "    f1 = go.Scatter(**kw)\n",
    "    f2 = go.Scatter(**kw1)\n",
    "    \n",
    "    fig.add_trace(f1, row=1, col=1)\n",
    "    fig.add_trace(f2, row=2, col=1)\n",
    "    fig.update_layout(template=template, height=500, width=1000, margin=dict(l=10, r=10, b=10, t=30))\n",
    "    return fig\n",
    "\n",
    "interact(print_val,v=slider);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f6bc3f-9c5f-4a39-8b6b-5f2c341ceeff",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "prices.index = pd.to_datetime(prices.index)\n",
    "ax={'sharpe': ax1, 'sortino': ax2}\n",
    "for i, v in ax.items():\n",
    "    p_tr = prices[i].resample(\"ME\").last()\n",
    "    p_ret = np.log(p_tr / p_tr.shift()).dropna().to_frame()\n",
    "    p_ret.columns = [\"Return\"]\n",
    "    windows = [year for year in range(p_ret.index.size, 0, -1)]\n",
    "    for period in windows:\n",
    "        p_ret[\"#{}\".format(period)] = p_ret.Return.rolling(period).mean()\n",
    "    triangle = p_ret.drop(columns = [\"Return\"])\n",
    "    triangle.index = triangle.index.to_period('M')\n",
    "    sns.heatmap(triangle, annot=False, cmap=\"RdYlGn\", vmin=-0.2/12, vmax=0.2/12, center=0, cbar=False, ax=v)\n",
    "\n",
    "# plt.figure(figsize=(80,50))\n",
    "plt.tick_params(axis = \"y\", labelright =True, labelleft=False, grid_alpha=.5)\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093a0d04-03ae-499f-a81b-672c3c744fde",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, sharey=True, figsize=(16, 6))\n",
    "axes[0].scatter(summary.loc[:, \"Risk\"], summary.loc[:, \"Return\"]*100, s=10, marker=\"x\", c=\"lime\")\n",
    "axes[0].scatter(port_summary.loc[:, \"Risk\"], port_summary.loc[:, \"Return\"]*100, s=8, c=port_summary.loc[:, \"Sharpe\"], cmap=\"coolwarm\",\n",
    "    vmin=port_summary.Sharpe.min(), vmax=port_summary.loc[msrp].Sharpe, alpha=.7)\n",
    "for i in summary.index:\n",
    "    axes[0].annotate(i, xy=(summary.loc[i, \"Risk\"]+0.0002, summary.loc[i, \"Return\"]*100+.5), size=8, c=\"lime\")\n",
    "\n",
    "axes[1].scatter(summary.loc[:, \"Risk\"], summary.loc[:, \"Return\"]*100, s=10, marker=\"x\", c=\"lime\")\n",
    "axes[1].scatter(port_summary.loc[:, \"Risk\"], port_summary.loc[:, \"Return\"]*100, s=8, c=port_summary.loc[:, \"Sortino\"], cmap=\"coolwarm\",\n",
    "    vmin=port_summary.Sortino.min(), vmax=port_summary.loc[msrp1].Sortino, alpha=.7)\n",
    "for i in summary.index:\n",
    "    axes[1].annotate(i, xy=(summary.loc[i, \"Risk\"]-0.1, summary.loc[i, \"Return\"]*100-1.5), size=8, c=\"lime\")\n",
    "\n",
    "axes[0].set_xlabel('Risk(std)')\n",
    "axes[0].set_ylabel('Return')\n",
    "axes[1].set_xlabel('Risk(std)')\n",
    "axes[1].set_ylabel('Return')\n",
    "\n",
    "axes[0].set_title(f\"Sharpe Ratio: ({port_summary.loc[msrp].Return*100:.1f}% return {str(start)[:4]}-{end[:4]})\")\n",
    "axes[1].set_title(f\"Sortino Ratio: ({port_summary.loc[msrp1].Return*100:.1f}% return {str(start)[:4]}-{end[:4]})\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b3fac0-eeea-4355-b1a6-f25a62181add",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Overlaps ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5289f6aa-7250-42cb-83ff-50a892a826f7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "g = net.Network(notebook=True, bgcolor='#111111', font_color='white', width=\"100%\", height=\"800px\")#, cdn_resources='in_line')\n",
    "# g.repulsion()\n",
    "g.physics = \"forceAtlas2Based\"\n",
    "# g.inherit_edge_colors(False)\n",
    "nxg=nx.complete_graph(0)\n",
    "for n in summary.index: # FIXME: colors of edges\n",
    "    if summary.loc[n]['category'] == 'INDEX':\n",
    "        continue\n",
    "    kw = {'label':n, 'shape':'box'} #'size':abs(summary.loc[n, 'Return'])*100\n",
    "    kw['title'] = textwrap.fill(funds[n]['summaryProfile'].get('longBusinessSummary', funds[n]['summaryProfile'].get('description')), 60)\n",
    "    if summary.loc[n, 'Return'] < 0:\n",
    "        kw['color'] = 'red'\n",
    "    kw['borderWidth'] = abs(summary.loc[n]['Return']) * 100\n",
    "    kw['group'] = summary.loc[n]['category']\n",
    "    nxg.add_node(n, **kw)\n",
    "    for h in funds[n].get('topHoldings',{}).get('holdings',{}):\n",
    "        nxg.add_node(h['symbol'], label=h['holdingName'], shape='text')\n",
    "        nxg.add_edge(n, h['symbol'], value=h['holdingPercent'], title=f\"{100*h['holdingPercent']:.1f}%\")\n",
    "g.from_nx(nxg)\n",
    "g.show(\".overlaps.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23460c77-38d5-4fde-973c-faa4fbc455b6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ms = range(20, 101, 10)\n",
    "dfmd = pd.DataFrame(index = ms, columns=idx['Adj Close'].columns)\n",
    "\n",
    "for finish in ms:\n",
    "    n, best = min([3, len(idx['Adj Close'].columns)//2]), {c:0 for c in idx['Adj Close'].columns}\n",
    "    for v in range(100):\n",
    "        t0 = int(v * (prices.shape[0] * finish / 100 / 100)) # Starting time for comparison\n",
    "        df = (prices.iloc[:int((prices.shape[0] * finish / 100))] / prices.iloc[t0]).dropna() # DataFrame normalized against Starting time prices\n",
    "        if t0 + 1 >= df.shape[0]:\n",
    "            continue\n",
    "        ratios = ann_risk_return(df.iloc[int(v * (df.shape[0] / 100)):])['Return'][:-2] * 100\n",
    "        for x in ratios.nlargest(n).index:\n",
    "            best[x] = 1 if not x in best else best[x]+1\n",
    "    summary['Top'] = [best[x] for x in sorted(best)] # Sample 100 intervals' to date for top N returns\n",
    "    weight = 'weight' if model == 'Sharpe' else 'weight1'\n",
    "    dfmd.loc[finish] = [best[x] for x in sorted(best)]\n",
    "    \n",
    "dfmd.index = [str(prices.iloc[int(prices.shape[0] * x / 100)].name)[:10] for x in range(10, 100, 10)]\n",
    "px.imshow(dfmd.T, template=template, color_continuous_scale=px.colors.sequential.Viridis, color_continuous_midpoint=55,\n",
    "          title=f\"In Top {n} Performers {dfmd.index[0]} ... {dfmd.index[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be5e3ca-40ae-4a03-8a90-582ed7b7f2e7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Obsolete"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4dcc3c80-689b-40ab-8a41-fc11206168bd",
   "metadata": {},
   "source": [
    "%%time\n",
    "cols = 2\n",
    "fig = make_subplots(rows=int((len(prices.columns)+1)/cols), cols=cols, shared_xaxes='all', vertical_spacing=.05, horizontal_spacing=.05,\n",
    "    subplot_titles=prices.columns, column_width=[1000/cols for i in range(cols)])\n",
    "premiums, rmses, currents, predicts, counter = [], [], [], [], 0\n",
    "for fund in prices.columns:\n",
    "    data, dataset, training_data_len = get_data(fund)\n",
    "    x_train, y_train, scaler, scaled_data = get_train()\n",
    "    pred_model = get_model(x_train, y_train)\n",
    "    predictions, rmse = get_predictions(scaler, scaled_data)\n",
    "    \n",
    "    rescale = 1 if fund in ['sharpe', 'sortino'] else idx.loc[start, 'Adj Close'][fund] / 100\n",
    "    train, valid = data[:training_data_len] * rescale, data[training_data_len:] * rescale\n",
    "    valid['Predictions'] = predictions * rescale\n",
    "    data[fund] = data[fund] * rescale\n",
    "    premium = valid.iloc[-1, 0]/valid.iloc[-1, 1] * 100 - 100\n",
    "    premiums.append(premium)\n",
    "    rmses.append(rmse)\n",
    "    currents.append(valid.iloc[-1, 0])\n",
    "    predicts.append(valid.iloc[-1, 1])\n",
    "\n",
    "    if fund in idx['LBAND'].columns:\n",
    "        fig_l = px.line(idx['LBAND'].filter([fund]), x=idx['LBAND'].filter([fund]).index, y=idx['LBAND'].filter([fund]).columns[0])\n",
    "        fig_u = px.line(idx['UBAND'].filter([fund]), x=idx['UBAND'].filter([fund]).index, y=idx['UBAND'].filter([fund]).columns[0])\n",
    "        fig_l.update_traces(line_color='#c0c0c0', line_width=1, hovertemplate='LBAND=%{y}<extra></extra>')\n",
    "        fig_u.update_traces(line_color='#c0c0c0', line_width=1, hovertemplate='UBAND=%{y}<extra></extra>')\n",
    "        fig.add_trace(fig_u.data[0], row=counter//cols+1, col=counter % cols + 1);\n",
    "    \n",
    "    fig_b = px.line(data, x=data.index, y=data.columns[0])\n",
    "    fig_b.update_traces(line_color='#0000ff', line_width=1, hovertemplate='Adj Close=%{y}<extra></extra>')\n",
    "    fig_r = px.line(valid, x=valid.index, y='Predictions')\n",
    "    fig_r.update_traces(line_color='#ff0000' if premium>0 else '#00ff00', line_width=abs(premium)+1, opacity=min([1, (abs(premium)/rmse) ** .5]), hovertemplate='Predictions=%{y}<extra></extra>')\n",
    "    fig.add_trace(fig_r.data[0], row=counter//cols+1, col=counter % cols + 1);\n",
    "    fig.add_trace(fig_b.data[0], row=counter//cols+1, col=counter % cols + 1);\n",
    "    if fund in idx['LBAND'].columns:\n",
    "        fig.add_trace(fig_l.data[0], row=counter//cols+1, col=counter % cols + 1); # So it'd be at the bottom of hover screen\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    target = ((idx.Low / idx.Open).quantile(0.3) * idx.Open).iloc[-1][fund] if not fund in ['sharpe', 'sortino'] else 0\n",
    "    text = f\"{fund}: {premium:.1f}% premium ({rmse:.1f} rmse). Predict: {valid.iloc[-1, 1]:.2f}.\"\n",
    "    if not fund in ['sharpe', 'sortino']:\n",
    "        text = text + f\" Buy: {target:.2f}\"\n",
    "    fig.layout['annotations'][counter].update({\"text\": text})\n",
    "    fig.update_yaxes(type=\"log\")\n",
    "\n",
    "    fig.update_layout(height=60*len(prices.columns)+60*counter, width=1450, margin=dict(l=10, r=10, b=10, t=30), template=template,\n",
    "            xaxis=dict(spikecolor=\"white\", spikethickness=.25, spikedash='dash', spikemode='toaxis+across+marker', spikesnap='cursor'),\n",
    "        spikedistance=4, hovermode='x unified', legend_traceorder=\"normal\")\n",
    "\n",
    "    counter += 1\n",
    "    fig.show();\n",
    "\n",
    "summary[\"current\"] = currents[:summary.shape[0]]\n",
    "summary[\"predict\"] = predicts[:summary.shape[0]]\n",
    "summary[\"premium\"] = premiums[:summary.shape[0]]\n",
    "summary[\"rmse\"] = rmses[:summary.shape[0]]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2e4fbcd5-b446-422a-96b1-def9d587410f",
   "metadata": {
    "tags": []
   },
   "source": [
    "if type(x) == str:\n",
    "    x=0\n",
    "x-=1 # Use previous day's data\n",
    "idx_index = idx.index\n",
    "idx.index = idx.index.astype(str)\n",
    "trend = (\n",
    "    (idx['Close'] > idx['tenkan_sen']) & (idx['tenkan_sen'] > idx['kijun_sen'])\n",
    ")|(\n",
    "    (idx['Close'] < idx['tenkan_sen']) & (idx['tenkan_sen'] < idx['kijun_sen'])\n",
    ")\n",
    "cloudposition = [idx.swaplevel(1,0, axis=1)[v].apply(compare_values_ichi, axis=1).iloc[x] for v in idx['Low'].columns]\n",
    "\n",
    "g = px.scatter(\n",
    "    idx.iloc[x],\n",
    "    text=[i.upper() if v else i.lower() for i, v in idx['signal_ichimoku'].iloc[x].items()],\n",
    "    x=idx['MACD_prc'].iloc[x], y=idx['RSI_prc'].iloc[x],\n",
    "    hover_name=[i.upper() if v else i.lower() for i, v in idx['signal_ichimoku'].iloc[x].items()],\n",
    "    hover_data=[idx.iloc[x]['Adj Close'], rsi_target(idx[:x]).values()],\n",
    "    color=idx['Adj Close'].pct_change().iloc[x].values*100, color_continuous_scale='RdYlGn', color_continuous_midpoint=0.0,\n",
    "    title=f\"RSI vs MACD Rankings as of {idx.index[x]}\", template=template,\n",
    "    symbol=idx.iloc[x]['symbol'], symbol_map=symbol_map,\n",
    ")\n",
    "g.add_shape(type='line', x0=50, y0=50, x1=100, y1=50, line=dict(color='red', dash='dash'))\n",
    "g.add_shape(type='line', x0=50, y0=50, x1=50, y1=100, line=dict(color='red', dash='dash'))\n",
    "g.add_shape(type='line', x0=0, y0=50, x1=50, y1=50, line=dict(color='yellow', dash='dash'))\n",
    "g.add_shape(type='line', x0=50, y0=0, x1=50, y1=50, line=dict(color='yellow', dash='dash'))\n",
    "kw = {\n",
    "    'marker': dict(\n",
    "        size=(2*idx['Adj Close'].pct_change().iloc[x] / idx['Adj Close'].pct_change().std())**2+5,\n",
    "        line=dict(width=3, color=idx['RSI'].iloc[x], cmax=2, cmin=-2, colorscale=\"RdYlGn\")\n",
    "    ),\n",
    "    'textfont': dict(color=[f\"rgba(255, 255, 255, 0.{8 if t else 2})\" for t in trend.iloc[x]]),\n",
    "    'textposition': cloudposition,\n",
    "}\n",
    "g.update_traces(**kw) # hovertemplate=s+'=%{y}<extra></extra>'\n",
    "g.update_layout(xaxis_title=\"MACD Frequency\", yaxis_title=\"RSI Frequency\", showlegend=False)\n",
    "g.update_coloraxes(showscale=False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7b26b6d2-b285-4a55-af78-044b26679dfc",
   "metadata": {
    "tags": []
   },
   "source": [
    "slider = widgets.IntSlider(min=20, max=100, value=100, step=20)\n",
    "def print_val(finish):\n",
    "    n, best = min([3, len(idx['Adj Close'].columns)//2]), {c:0 for c in idx['Adj Close'].columns}\n",
    "    for v in range(100):\n",
    "        t0 = int(v * (prices.shape[0] * finish / 100 / 100)) # Starting time for comparison\n",
    "        df = (prices.iloc[:int((prices.shape[0] * finish / 100))] / prices.iloc[t0]).dropna() # DataFrame normalized against Starting time prices\n",
    "        ratios = ann_risk_return(df.iloc[int(v * (df.shape[0] / 100)):])['Return'][:-2] * 100\n",
    "        largest_values = ratios.nlargest(n)\n",
    "        for x in largest_values.index:\n",
    "            best[x] = 1 if not x in best else best[x]+1\n",
    "    weight = 'weight' if model == 'Sharpe' else 'weight1'\n",
    "    return px.bar(summary, title=f\"In Top {n} Performers {str(df.iloc[0].name)[:10]} ... {str(df.iloc[-1].name)[:10]}\", color=category,\n",
    "                  y=[best[x] for x in sorted(best)], template=template, opacity=[(x/max(summary[weight]))**.5 for x in summary[weight]])\n",
    "interact(print_val,finish=slider);"
   ]
  },
  {
   "cell_type": "raw",
   "id": "12d96a56-aa42-4c06-bda2-c412ab93d9f3",
   "metadata": {
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33bb6c51-a371-490e-aef5-ad58a1bd8159",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379ddc03-860b-4682-a15a-83a47038af3f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Screener"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e6d1c3-fb11-4e6e-920c-38001bf411c4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "droplist = \" \".join((TEST, \" \".join((categories.values()))))\n",
    "shortlist = []\n",
    "for r in recommendations.values():\n",
    "    for v in r.values():\n",
    "        if v=='No data found':\n",
    "            continue\n",
    "        for rec in v['recommendedSymbols']:\n",
    "            if not (rec['symbol'] in droplist):\n",
    "                shortlist.append(rec['symbol'])\n",
    "profiles = {n:Ticker(n).fund_profile[n] for n in shortlist}\n",
    "for prop in ['maxAge', 'styleBoxUrl']:\n",
    "    for k,v in profiles.items():\n",
    "        if prop in v:\n",
    "            del v[prop]\n",
    "shortlist = [p for p, v in profiles.items() if 'categoryName' in v and not 'Leveraged' in v['categoryName']]\n",
    "\" \".join(sorted({*shortlist}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070ff3a9-8b21-4fc0-a95a-23bf9c8f2990",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Recommendations\n",
    "g = net.Network(notebook=True, bgcolor='#111111', font_color='white', width=\"100%\", height=\"800px\")#, cdn_resources='in_line')\n",
    "g.repulsion()\n",
    "g.physics = \"forceAtlas2Based\"\n",
    "nxg=nx.complete_graph(0)\n",
    "for n in summary.index:\n",
    "    if n == '^VIX':\n",
    "        continue\n",
    "    kw = {'label':n, 'shape':'box'}\n",
    "    kw['group'] = summary.loc[n]['category']\n",
    "    kw['title'] = textwrap.fill(funds[n]['summaryProfile'].get('longBusinessSummary', funds[n]['summaryProfile'].get('description')), 60)\n",
    "    nxg.add_node(n, **kw)\n",
    "    if list(recommendations[n].values()) == ['No data found']:\n",
    "        continue\n",
    "    for h in list(recommendations[n].values())[0]['recommendedSymbols']:\n",
    "        if not h['symbol'] in shortlist:\n",
    "            continue\n",
    "        nxg.add_node(h['symbol'], label=h['symbol'], shape='text', title=json.dumps(profiles[h['symbol']], indent=2))\n",
    "        nxg.add_edge(n, h['symbol'], value=h['score'], title=100*h['score'])\n",
    "g.from_nx(nxg)\n",
    "g.show(\".recommendations.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd504830-d39a-436b-b2a7-7b40ab7f9cd3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "s = Screener()\n",
    "print([x for x in s.available_screeners if 'etf' in x and not 'asia' in x and not 'europe' in x])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a7d6e682-185e-436f-b7f1-71801cfe0b7b",
   "metadata": {},
   "source": [
    "print(json.dumps(s.get_screeners(['top_etfs_us', 'cheapest_etfs', 'fifty_two_wk_losers_etfs', 'precious_metal_etfs', 'top_performing_etfs'], 5), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52edc60d-7d81-4058-a909-c54e05a02062",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "screener = ['fifty_two_wk_losers_etfs', 'cheapest_etfs', 'top_etfs_us'] #'top_performing_etfs', 'precious_metal_etfs'\n",
    "def g(row):\n",
    "    return [str(r) for r in row.values]\n",
    "    \n",
    "def bold_row(row):\n",
    "    return ['font-weight: bold' if 'ChangePercent' in row.name else '' for v in row]\n",
    "\n",
    "def bold_index(s):\n",
    "    return '<b>{}</b>'.format(s)\n",
    "\n",
    "def h_hi(row):\n",
    "    return ['background-color: lightgreen']*len(row.values) if 'ChangePercent' in row.name else ['']*len(row.values)\n",
    "\n",
    "droprows=[\"shortName\", 'exchange', 'firstTradeDateMilliseconds', 'messageBoardId', 'dividendDate', 'fiftyTwoWeekLowChangePercent',\n",
    "          'fiftyTwoWeekHighChangePercent', 'fiftyDayAverageChangePercent', 'twoHundredDayAverageChangePercent', 'fiftyTwoWeekLowChange',\n",
    "          'fiftyTwoWeekHighChange', 'regularMarketChange', 'isEarningsDateEstimate', 'postMarketChangePercent', 'askSize', 'bidSize',\n",
    "          'ipoExpectedDate', 'epsTrailingTwelveMonths', 'sharesOutstanding', 'bookValue', 'marketCap', 'netAssets']\n",
    "quotes = [i for q in s.get_screeners(screener, 48).values() for i in q['quotes'] if not i['symbol'] in droplist]\n",
    "df = pd.json_normalize(quotes).set_index('symbol').T\n",
    "df.drop(df.index[:7], inplace=True)\n",
    "df.drop([c for c in df.index if 'Time' in c], inplace=True)\n",
    "df.dropna(axis=1, subset=['longName'], inplace=True)\n",
    "\n",
    "regex = re.compile('|'.join(['everage', \"Ether\", 'Bitcoin', 'Bond', \"Ultra\", \"Short\", \"Long\", 'Hedge', 'Option', 'Covered Call', 'Treasury',\n",
    "                             \"Trust\", \"Daily\", \"Monthly\", 'Weekly', 'Asia', 'China', 'Emerging', 'iShares MSCI']))\n",
    "df.drop(columns=df.columns[df.loc['longName'].str.contains(regex)], axis=1, inplace=True)\n",
    "\n",
    "for i in df.index:\n",
    "    if 1 == len(set(g(df.loc[i,:]))):\n",
    "        droprows.append(i)\n",
    "df.drop(droprows, inplace=True, errors='ignore')\n",
    "df = df.sort_values(by=['fiftyTwoWeekChangePercent'], axis=1, ascending=False)\n",
    "df = df.fillna('')\n",
    "\n",
    "df.drop(droplist, axis=1, errors='ignore', inplace=True)\n",
    "df.head(60).style.apply(h_max, axis=1).apply(h_min, axis=1).apply(bold_row, axis=1).apply(h_hi, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819f3d97-5547-4a8f-81d4-1f1c8628092f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\" \".join(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c879ca-7f45-4ec9-8e26-e0f0be6637d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Algo Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0544b96e-a9cc-4112-9d48-42c24e3e4c66",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "algo=(1 + idx['Adj Close'].pct_change() * idx['position_ema'].shift(1)).cumprod()\n",
    "px.line(algo, template=template, log_y=True, title=\"Algo EMA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44aa2861-4436-481b-b75b-4a21ee72d135",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "algo=(1 + idx['Adj Close'].pct_change() * idx['position_rsi'].shift(1)).cumprod()\n",
    "px.line(algo, template=template, log_y=True, title=\"Algo RSI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feecc9f7-12cf-492e-8ca5-80cd19eabc0e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def calc_positions_ichimoku(d):\n",
    "#     global idx\n",
    "#     columns = d['Low'].columns\n",
    "#     condition = np.where(\n",
    "#         # (d['Close'] > d['tenkan_sen']) & (d['tenkan_sen'] > d['kijun_sen']) &\n",
    "#         ((d['Close'] > d['tenkan_sen']) & (d['Close'] > d['kijun_sen'])) & (d['tenkan_sen'] > d['kijun_sen']) &\n",
    "#         (\n",
    "#             ((d['Close'] > d['senkou_span_a']) & (d['Close'] > d['senkou_span_b'])) |\n",
    "#             ((d['Close'] < d['senkou_span_a']) & (d['Close'] < d['senkou_span_b']) & (d['senkou_span_a'] < d['senkou_span_b']))\n",
    "#         ), 0, 1\n",
    "#     )\n",
    "#     sgn = pd.DataFrame(condition, columns=columns, index=d.index)\n",
    "#     sgn.columns = pd.MultiIndex.from_product([['signal_ichimoku'], columns])\n",
    "#     pos = sgn.diff().fillna(0)\n",
    "#     pos.columns = pd.MultiIndex.from_product([['position_ichimoku'], columns])\n",
    "#     idx.drop(columns='signal_ichimoku', inplace=True, errors='ignore')\n",
    "#     idx.drop(columns='position_ichimoku', inplace=True, errors='ignore')\n",
    "#     idx = idx.join(pos)\n",
    "#     idx = idx.join(sgn)\n",
    "# calc_positions_ichimoku(idx)\n",
    "\n",
    "algo=(1 + idx['Adj Close'].pct_change() * idx['position_ichimoku'].shift(1)).cumprod()\n",
    "px.line(algo, template=template, log_y=True, title=\"Algo Ichimoku\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e45dd3e-3c33-4998-9e10-91662301fce1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4546d0d5-8c29-4f60-a668-917adf077d0d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda-fin:Python",
   "language": "python",
   "name": "conda-env-.conda-fin-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
