{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07e407a",
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "############\n",
    "# https://stackoverflow.com/questions/69800749/using-python-to-get-holdings-and-allocation-of-etfs\n",
    "# conda env create -f environment.yml\n",
    "# conda install -f environment.yml\n",
    "# conda update -n base conda\n",
    "# conda env update --file environment.yml --prune\n",
    "# print(\"https://www.etfdb.com\")\n",
    "print(\"https://www.etfrc.com/funds/overlap.php\")\n",
    "TRADITIONAL = 'VYM VOT MGK VIG VGT VOO VDE VCR VHT VFH VUG'\n",
    "# \"AIRR CLSE CRPT HTUS IGM KBWP MGK PAVE PKB RSHO SLX SPSM VCR VDE VFH VGT VHT VIG VOO VOT VUG VYM XBI XHB\"\n",
    "ROTH = 'SPYG SCHG QQQ VGT CRPT IGM PAVE PKB XHB' # Roth 2024.03.14. 04.01 -IVW VOO MGK VTI IUSG VUG\n",
    "\n",
    "BASE = 'VOT VOO VTI FLMVX FXAIX'\n",
    "CONSTRUCTION = 'AIRR PKB XHB ITB'\n",
    "GROWTH = 'MGK VGT VUG QQQ IVW SCHG SPYG IUSG FCNKX JDMNX MITJX VIGIX'\n",
    "DIV = 'VYM VIG'\n",
    "ENERGY = 'AMZA URNM VDE'\n",
    "INSURANCE = 'KBWP'\n",
    "SECTORS = 'VOX VCR VDC VFH VHT VIS VAW VPU RSHO PRN'\n",
    "INTERNATIONALS = 'VEU VSS VEA VWO VGK VPL VNQI VXUS VT'\n",
    "CRYPTO = 'CRPT'# DAPP BITQ BKCH SATO WGMI IBLC # BITX (2023-06-27) GBTC IBIT (2024-1-11)\n",
    "INFRA = 'PAVE'# IGF IFRA NFRA EMIF RBLD\n",
    "AI = 'IGM IYW FTEC FDN'\n",
    "\n",
    "BENCH = 'VOO CRPT SPSM PAVE '# KBWP PAVE IGM VGT QMOM URNM AMZA PKB=XHB SLX\n",
    "TEST = BENCH\n",
    "TEST = BENCH + 'CLSE XBI IAI KCE PSP XMMO XSMO UTES AIRR PKB KBWP XHB HTUS' # HRTS CBLS USE GCAD SLX VDE\n",
    "start = '2020-11-03'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e3e854-f95c-4411-8dbb-ef9bf2035539",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import libraries and pull data\n",
    "import datetime\n",
    "import warnings\n",
    "import re\n",
    "import json\n",
    "import textwrap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import pandas_ta as ta\n",
    "import yfinance as yf\n",
    "#import quantstats as qs\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cufflinks as cf\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from ipywidgets import widgets, interact, interactive\n",
    "from scipy import stats\n",
    "#from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import Dense, LSTM, Activation\n",
    "from IPython.display import display, clear_output, HTML\n",
    "from yahooquery import Ticker, Screener\n",
    "from pyvis import network as net\n",
    "import networkx as nx\n",
    "\n",
    "cf.go_offline()\n",
    "pio.renderers.default = 'iframe'\n",
    "plt.style.use('dark_background')\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"yfinance\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"cufflinks\")\n",
    "warnings.filterwarnings(\"ignore\", \"is_categorical_dtype\")\n",
    "warnings.filterwarnings(\"ignore\", \"use_inf_as_na\")\n",
    "warnings.filterwarnings(\"ignore\", \"warn_singular\")\n",
    "warnings.simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "template = 'plotly_dark'\n",
    "pd.options.display.float_format = \"{:,.2f}\".format\n",
    "\n",
    "EPOCH=64\n",
    "EPOCH=32\n",
    "NOP = 20000 # Number of random portfolio sets\n",
    "risk_free_return = .05\n",
    "model = 'Sharpe'\n",
    "categories = {\n",
    "    \"ai\": AI,\n",
    "    \"base\": BASE,\n",
    "    \"construction\": CONSTRUCTION,\n",
    "    \"crypto\": CRYPTO,\n",
    "    \"div\": DIV,\n",
    "    \"energy\": ENERGY,\n",
    "    \"growth\": GROWTH,\n",
    "    \"infra\": INFRA,\n",
    "    \"insurance\": INSURANCE,\n",
    "    \"internationals\": INTERNATIONALS,\n",
    "    \"sectors\": SECTORS,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4376d56a-1452-43ea-9176-e9091a997ef0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_positions_ichimoku(d):\n",
    "    global idx\n",
    "    columns = d['Low'].columns\n",
    "    # Adding signals for buy/ sell\n",
    "    sgn = pd.DataFrame(np.where((d['tenkan_sen'] > d['kijun_sen']) & (d['Close'] > d['tenkan_sen']), 1, 0), columns=columns, index=d.index)\n",
    "    sgn.columns = pd.MultiIndex.from_product([['signal_ichimoku'], columns])\n",
    "    pos = sgn.diff().fillna(0)\n",
    "    pos.columns = pd.MultiIndex.from_product([['position_ichimoku'], columns])\n",
    "    idx.drop(columns='signal_ichimoku', inplace=True, errors='ignore')\n",
    "    idx.drop(columns='position_ichimoku', inplace=True, errors='ignore')\n",
    "    idx = idx.join(pos)\n",
    "    idx = idx.join(sgn)\n",
    "\n",
    "def calc_positions_rsi(d):\n",
    "    global idx\n",
    "    columns = d['Low'].columns\n",
    "    # Adding signals for buy/ sell\n",
    "    indicator='RSI'\n",
    "    period=42\n",
    "    sgn = pd.DataFrame(np.where(d[indicator].rolling(window=period).mean() - idx[indicator] - .3 < 0, 0, 1), columns=columns, index=d.index)\n",
    "    sgn.columns = pd.MultiIndex.from_product([['signal_rsi'], columns])\n",
    "    pos = sgn.diff().fillna(0)\n",
    "    pos.columns = pd.MultiIndex.from_product([['position_rsi'], columns])\n",
    "    idx.drop(columns='signal_rsi', inplace=True, errors='ignore')\n",
    "    idx.drop(columns='position_rsi', inplace=True, errors='ignore')\n",
    "    idx = idx.join(pos)\n",
    "    idx = idx.join(sgn)\n",
    "    \n",
    "def calc_positions_ema(d):\n",
    "    global idx\n",
    "    columns = d['Low'].columns\n",
    "    # Adding signals for buy/ sell\n",
    "    sgn = pd.DataFrame(np.where(d['EMAW'] > d['EMAM'], 1, 0), columns=columns, index=d.index)\n",
    "    sgn.columns = pd.MultiIndex.from_product([['signal_ema'], columns])\n",
    "    pos = sgn.diff().fillna(0)\n",
    "    pos.columns = pd.MultiIndex.from_product([['position_ema'], columns])\n",
    "    idx.drop(columns='signal_ema', inplace=True, errors='ignore')\n",
    "    idx.drop(columns='position_ema', inplace=True, errors='ignore')\n",
    "    idx = idx.join(pos)\n",
    "    idx = idx.join(sgn)\n",
    "\n",
    "def price_bands(period = 42, multiplier = 1.8): # Calculate price bands\n",
    "    global idx\n",
    "    \n",
    "    columns = idx['Low'].columns\n",
    "    \n",
    "    std = idx['Adj Close'].rolling(window=period).std()\n",
    "    std.columns = pd.MultiIndex.from_product([['STD'], columns])\n",
    "    idx = idx.join(std)\n",
    "    \n",
    "    ma = idx['Adj Close'].rolling(window=period).mean()\n",
    "    ma.columns = pd.MultiIndex.from_product([['MA'], columns])\n",
    "    idx = idx.join(ma)\n",
    "    \n",
    "    uband = idx['MA'] + multiplier * idx['STD']\n",
    "    uband.columns = pd.MultiIndex.from_product([['UBAND'], columns])\n",
    "    idx = idx.join(uband)\n",
    "    \n",
    "    lband = idx['MA'] - multiplier * idx['STD']\n",
    "    lband.columns = pd.MultiIndex.from_product([['LBAND'], columns])\n",
    "    idx = idx.join(lband)\n",
    "\n",
    "    emaw = idx['Adj Close'].ewm(span=5, adjust=False).mean()\n",
    "    emaw.columns = pd.MultiIndex.from_product([['EMAW'], columns])\n",
    "    idx = idx.join(emaw)\n",
    "    \n",
    "    emam = idx['Adj Close'].ewm(span=21, adjust=False).mean()\n",
    "    emam.columns = pd.MultiIndex.from_product([['EMAM'], columns])\n",
    "    idx = idx.join(emam)\n",
    "\n",
    "    # strength = 2 * (idx['Adj Close'] - idx['UBAND']) / (idx['UBAND'] - idx['LBAND']) + 1\n",
    "    # strength.columns = pd.MultiIndex.from_product([['strength'], columns])\n",
    "    # idx = idx.join(strength)\n",
    "    \n",
    "    # Moving Average Convergence Divergence\n",
    "    mdl = idx['EMAM'] - idx['EMAW']\n",
    "    sgl = mdl.ewm(span=16, adjust=False).mean()\n",
    "    mdh = sgl - mdl\n",
    "\n",
    "    # mdl.columns = pd.MultiIndex.from_product([['MACD_Line'], columns])\n",
    "    # sgl.columns = pd.MultiIndex.from_product([['Signal_Line'], columns])\n",
    "    mdh.columns = pd.MultiIndex.from_product([['MACD'], columns])\n",
    "    \n",
    "    # idx = idx.join(mdl)\n",
    "    # idx = idx.join(sgl)\n",
    "    idx = idx.join(mdh)\n",
    "\n",
    "    # Relative Strength Index\n",
    "    rsi = calculate_rsi(idx)/25-2\n",
    "    rsi.columns = pd.MultiIndex.from_product([['RSI'], columns])\n",
    "    idx = idx.join(rsi)\n",
    "    \n",
    "    idx = calc_ichimoku(idx)\n",
    "    calc_positions_ichimoku(idx)\n",
    "    calc_positions_ema(idx)\n",
    "    calc_positions_rsi(idx)\n",
    "\n",
    "    summary['UBAND'] = idx['UBAND'].iloc[-1]\n",
    "    summary['Adj Close'] = idx['Adj Close'].iloc[-1]\n",
    "    summary['LBAND'] = idx['LBAND'].iloc[-1]\n",
    "    # summary['RSI'] = idx['RSI'].iloc[-1]\n",
    "    # summary['MACD'] = idx['MACD'].iloc[-1]\n",
    "\n",
    "    for indicator in ['MACD', 'RSI']:\n",
    "        summary[f\"{indicator}_prc\"] = 100 - (idx[indicator] < idx[indicator].iloc[-1]).mean() * 100\n",
    "\n",
    "def calculate_rsi(data, window=10):\n",
    "    delta = data['Adj Close'].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    rs = gain / loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi\n",
    "\n",
    "def fillcol(d):\n",
    "    np.where(d['senkou_span_a'] > d['senkou_span_b'], 'green', 'red')\n",
    "    # np.where(df['A'] > 1, df['B'], 0)\n",
    "    \n",
    "#Calculate ichimoku \n",
    "def calc_ichimoku(d, tenkan_window=9, kijun_window=26, senkou_span_b_window=52, cloud_displacement=26, chikou_shift=-26):\n",
    "    last_date = d['Low'].dropna().index[-1]\n",
    "    if type(d['Low']) == pd.core.frame.DataFrame:\n",
    "        columns = d['Low'].columns\n",
    "        # Tenkan-sen (Conversion Line): (9-period high + 9-period low)/2))\n",
    "        nine_period_high = d['High'].rolling(window= tenkan_window).max()\n",
    "        nine_period_low = d['Low'].rolling(window= tenkan_window).min()\n",
    "        tenkan_sen = (nine_period_high + nine_period_low) /2\n",
    "        tenkan_sen.columns = pd.MultiIndex.from_product([['tenkan_sen'], columns])\n",
    "        d = d.join(tenkan_sen)\n",
    "\n",
    "        # Kijun-sen (Base Line): (26-period high + 26-period low)/2))\n",
    "        period26_high = d['High'].rolling(window=kijun_window).max()\n",
    "        period26_low = d['Low'].rolling(window=kijun_window).min()\n",
    "        kijun_sen = (period26_high + period26_low) / 2\n",
    "        kijun_sen.columns = pd.MultiIndex.from_product([['kijun_sen'], columns])\n",
    "        d = d.join(kijun_sen)\n",
    "\n",
    "    else:\n",
    "        # Step 2: Create a new date range for the next 26 business days\n",
    "        new_dates = pd.date_range(start=last_date+pd.Timedelta(days=1), periods=kijun_window, freq=pd.offsets.BDay())\n",
    "        # Step 3: Convert the DatetimeIndex to a DateIndex (i.e., remove the time part)\n",
    "        new_dates = new_dates.date  # This will convert the index to date type\n",
    "        # Step 4: Create a new dataframe with the new business dates (as date type index)\n",
    "        new_data = pd.DataFrame(index=new_dates)\n",
    "        # Step 5: Append the new rows to the original dataframe\n",
    "        d = pd.concat([d, new_data])\n",
    "\n",
    "        # Senkou Span A (Leading Span A): (Conversion Line + Base Line)/2))\n",
    "        d['senkou_span_a'] = ((d['tenkan_sen'] + d['kijun_sen']) / 2).shift(cloud_displacement)\n",
    "\n",
    "        # Senkou Span B (Leading Span B): (52-period high + 52-period low)/2))\n",
    "        period52_high = d['High'].rolling(window=senkou_span_b_window).max()\n",
    "        period52_low = d['Low'].rolling(window=senkou_span_b_window).min()\n",
    "        d['senkou_span_b'] = ((period52_high + period52_low) / 2).shift(cloud_displacement)\n",
    "\n",
    "        # The most current closing price plotted 26 time periods behind (optional)\n",
    "        d['chikou_span'] = d['Close'].shift(-chikou_shift)\n",
    "    return d\n",
    "    \n",
    "def plot2_ichimoku(d, ticker_name='', INCREASING_COLOR='green', DECREASING_COLOR='red', show_rangeslider=False):\n",
    "    fig = go.Figure(data=[go.Candlestick(x=d.index, open=d.Open, high=d.High, low=d.Low, close=d.Close,\n",
    "         increasing_line_color=INCREASING_COLOR, decreasing_line_color=DECREASING_COLOR, showlegend=False)])\n",
    "    kw = {'x': d.index, 'type': 'scatter', 'mode':'lines', 'visible':'legendonly'}\n",
    "\n",
    "    # Add TenkenSen to plot\n",
    "    fig.add_trace(go.Scatter(y=d['tenkan_sen'], name='tenkan_sen', line=dict(color='#33BDFF', width=1), **kw))\n",
    "    # Add kijun_sen to plot\n",
    "    fig.add_trace(go.Scatter(y=d['kijun_sen'], name='kijun_sen', line=dict(color='#F1F316', width=1), **kw))\n",
    "\n",
    "    kw = {'x': d.index, 'type': 'scatter', 'mode':'lines', 'showlegend': False}\n",
    "    # Add senkou_span_a to plot\n",
    "    # fig.add_trace(go.Scatter(y=d['senkou_span_a'], name='senkou_span_a', line=dict(color='#228B22', width=1), **kw))\n",
    "    fig.add_trace(go.Scatter(y=np.where(d['senkou_span_a'] > d['senkou_span_b'], d['senkou_span_a'], d['senkou_span_b']), name='senkou_span_max', line=dict(color='#228B22', width=0), **kw))\n",
    "    fig.add_trace(go.Scatter(\n",
    "        y=d['senkou_span_b'], \n",
    "        fill='tonexty',\n",
    "        fillcolor='rgba(0, 128, 0, 0.25)',\n",
    "        line=dict(color='rgba(0, 128, 0, 0.1)'),\n",
    "        name='senkou_span_a above',\n",
    "        **kw\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Scatter(y=np.where(d['senkou_span_b'] > d['senkou_span_a'], d['senkou_span_b'], d['senkou_span_a']), name='senkou_span_min', line=dict(color='#228B22', width=0), **kw))\n",
    "    fig.add_trace(go.Scatter(\n",
    "        y=d['senkou_span_a'], \n",
    "        fill='tonexty',\n",
    "        fillcolor='rgba(128, 0, 0, 0.25)',\n",
    "        line=dict(color='rgba(128, 0, 0, 0.1)'),\n",
    "        name='senkou_span_b above',\n",
    "        **kw\n",
    "    ))\n",
    "\n",
    "    # Add chikou_span to plot\n",
    "    # fig.add_trace(go.Scatter(y=d['chikou_span'], name='chikou_span', line=dict(color='#D105F5', width=1), **kw))\n",
    "    fig.update_layout(xaxis_rangeslider_visible=show_rangeslider)\n",
    "\n",
    "    fig.update_layout(\n",
    "        # title='Ichimoku',\n",
    "        yaxis_title=f'{ticker_name} Price',\n",
    "        xaxis_title='Date',\n",
    "        legend=dict(orientation='h', y=0.1, x=0.1, yanchor='top'),\n",
    "        margin=dict(t=40, b=40, r=40, l=40),\n",
    "        yaxis=dict(type='log'),\n",
    "        template=template,\n",
    "    )\n",
    "    return fig #.show()\n",
    "\n",
    "def get_model(x_train, y_train):\n",
    "    pred_model = Sequential()\n",
    "    pred_model.add(LSTM(50, return_sequences=True, input_shape=(x_train.shape[1], 1)))\n",
    "    pred_model.add(LSTM(50, return_sequences=False))\n",
    "    # pred_model.add(Dense(25))\n",
    "    pred_model.add(Dense(25, activation='relu'))\n",
    "    pred_model.add(Dense(1))\n",
    "    pred_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    pred_model.fit(x_train, y_train, batch_size=32, epochs=EPOCH, verbose=0)\n",
    "    return pred_model\n",
    "\n",
    "def get_predictions(scaler, scaled_data):\n",
    "    # Create the testing data set\n",
    "    # Create a new array containing scaled values \n",
    "    test_data = scaled_data[training_data_len - 60: , :]\n",
    "    x_test, y_test = [], dataset[training_data_len:, :]\n",
    "    for i in range(60, len(test_data)):\n",
    "        x_test.append(test_data[i-60:i, 0])\n",
    "        \n",
    "    # Convert the data to a numpy array\n",
    "    x_test = np.array(x_test)\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1)) # Reshape the data\n",
    "    # Get the models predicted price values \n",
    "    predictions = pred_model.predict(x_test)\n",
    "    predictions = scaler.inverse_transform(predictions)\n",
    "    rmse = np.sqrt(np.mean(((predictions - y_test) ** 2))) # root mean squared error\n",
    "    return (predictions, rmse)\n",
    "\n",
    "def get_train():\n",
    "    # Scale the data\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    # scaler = StandardScaler()\n",
    "\n",
    "    scaled_data = scaler.fit_transform(dataset)\n",
    "    # Create the scaled training data set\n",
    "    train_data = scaled_data[0:int(training_data_len), :]\n",
    "    # Split the data into x_train and y_train data sets\n",
    "    x_train, y_train = [], []\n",
    "    for i in range(60, len(train_data)):\n",
    "        x_train.append(train_data[i-60:i, 0])\n",
    "        y_train.append(train_data[i, 0])\n",
    "    # Convert the x_train and y_train to numpy arrays \n",
    "    x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "    # Reshape the data\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "    return (x_train, y_train, scaler, scaled_data)\n",
    "\n",
    "def get_data(fund):\n",
    "    #Create a new dataframe with only one data column\n",
    "    data = prices.filter([fund])\n",
    "    #Convert the dataframe to a numpy array\n",
    "    dataset = data.values\n",
    "    #Get the number of rows to train the model on\n",
    "    training_data_len = int(np.ceil(len(dataset) * .8))\n",
    "    training_data_len\n",
    "    return (data, dataset, training_data_len)\n",
    "\n",
    "def ann_risk_return(df):\n",
    "    rdf = df.agg([\"mean\", \"std\"]).T\n",
    "    rdf.columns = [\"Return\", \"Risk\"]\n",
    "    rdf.Return = (df.iloc[-1] / df.iloc[0]) ** (1/(((df.index[-1]-df.index[0]).days)/365)) - 1\n",
    "    rdf.Risk = rdf.Risk * np.sqrt(252)\n",
    "    return rdf\n",
    "\n",
    "def get_sortino(df):\n",
    "    returns = df.pct_change(1).dropna()\n",
    "    downside_returns = returns[returns < 0]\n",
    "    downside_std = np.std(downside_returns, axis=0)\n",
    "    sortino_ratio = returns.mean() / downside_std\n",
    "    return sortino_ratio\n",
    "\n",
    "def get_parent(ticker):\n",
    "    for parent in categories:\n",
    "        if ticker in (categories[parent]).split():\n",
    "            return parent\n",
    "    return summary.loc[ticker,'category']\n",
    "\n",
    "def h_max(s):\n",
    "    try:\n",
    "        is_max = s.astype('float') == s.max()\n",
    "        return ['color: green' if cell else '' for cell in is_max]\n",
    "    except:\n",
    "        return ['' for cell in s]\n",
    "\n",
    "def h_min(s):\n",
    "    try:\n",
    "        is_min= s.astype('float') == s.min()\n",
    "        return ['color: blue' if cell else '' for cell in is_min]\n",
    "    except:\n",
    "        return ['' for cell in s]\n",
    "\n",
    "def h_bull(s):\n",
    "    try:\n",
    "        is_bs = s.astype('str').str.contains('ullish') & ~s.astype('str').str.contains('earish') & ~s.astype('str').str.contains('Weak') & ~s.astype('str').str.contains(' one ')\n",
    "        return ['color: green' if cell else '' for cell in is_bs]\n",
    "    except:\n",
    "        return ['' for cell in s]\n",
    "\n",
    "def h_bear(s):\n",
    "    try:\n",
    "        is_bs = s.astype('str').str.contains('earish') & ~s.astype('str').str.contains('ullish') & ~s.astype('str').str.contains('Weak') & ~s.astype('str').str.contains(' one ')\n",
    "        return ['color: red' if cell else '' for cell in is_bs]\n",
    "    except:\n",
    "        return ['' for cell in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be94d7a-689b-4aff-8eba-0ef3a22ea1db",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tix = \" \".join(sorted(set(TEST.split())))\n",
    "for _ in range(4):\n",
    "    kw = {'start': start}\n",
    "    end = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    idx = yf.download(tix, **kw)\n",
    "    idx.index = idx.index.date\n",
    "    if idx['Adj Close'].index[0] != idx['Adj Close'].dropna().index[0]:\n",
    "        start = idx['Adj Close'].dropna().index[0]\n",
    "        print(f\"\\nCommon start: {start}\")\n",
    "        display(idx['Adj Close'][:start].fillna(''))\n",
    "        idx=idx.loc[start:]\n",
    "    # FIXME: Warning: some futures ETFs show NaN for current trading day\n",
    "    adj_prices = idx['Adj Close'].copy()\n",
    "    if any(adj_prices.iloc[-1].isna()):\n",
    "        print(\"Missing data from today!!!\")\n",
    "        columns_with_na_in_last_row = adj_prices.columns[adj_prices.isna().iloc[-1]].tolist()\n",
    "        print(f\"Drop {columns_with_na_in_last_row}\" + 10*\"\\n\")\n",
    "        tix = adj_prices.columns[~adj_prices.isna().iloc[-1]].tolist()\n",
    "    else:\n",
    "        break\n",
    "display(100*adj_prices.pct_change(1, fill_method=None).tail())\n",
    "# idx.dropna(inplace=True) # Crypto currency trades when stock market is closed\n",
    "\n",
    "prices = idx['Adj Close'].div(idx['Adj Close'].iloc[0]).mul(100)\n",
    "summary = pd.DataFrame(index=idx['Adj Close'].columns)\n",
    "tickers = {n: Ticker(n) for n in summary.index}\n",
    "funds = {n: t.all_modules[n] for n, t in tickers.items()}\n",
    "holdings = {fund:funds[fund][\"topHoldings\"]['holdings'] for fund in funds if funds[fund].get('topHoldings')}\n",
    "recommendations = {n: t.recommendations for n, t in tickers.items()}\n",
    "insights = {n: t.technical_insights[n] for n, t in tickers.items()}\n",
    "ret = prices.pct_change().dropna()\n",
    "types = []\n",
    "for fund in funds:\n",
    "    if 'CRYPTOCURRENCY' == funds[fund][\"quoteType\"]['quoteType']: # Crypto\n",
    "        types.append(funds[fund][\"quoteType\"]['quoteType'])\n",
    "    elif 'ETF' == funds[fund][\"quoteType\"]['quoteType']:\n",
    "        types.append(funds[fund][\"fundProfile\"]['categoryName'])\n",
    "    else: #'EQUITY' == funds[fund][\"quoteType\"]['quoteType'] = Stock\n",
    "        types.append(funds[fund][\"assetProfile\"]['sector'])\n",
    "summary['category'] = types\n",
    "\n",
    "summary = pd.concat((summary, ann_risk_return(prices.div(100))), axis=1)\n",
    "summary['trailingPE'] = [funds[fund][\"summaryDetail\"].get('trailingPE',0) for fund in funds]\n",
    "summary[\"Sharpe\"] = (summary[\"Return\"].sub(risk_free_return))/summary[\"Risk\"]\n",
    "summary[\"TotalRisk\"] = np.power(summary.Risk, 2)\n",
    "summary[\"SystRisk\"] = (prices.div(100).cov()*252).loc[:,'VOO' if 'VOO' in prices.columns else prices.columns[-1]]\n",
    "summary[\"UnsystRisk\"] = summary[\"TotalRisk\"].sub(summary[\"SystRisk\"])\n",
    "json_struct = json.loads(pd.DataFrame(insights).drop(['upsell', 'symbol'], errors='ignore').T.to_json(orient=\"records\"))\n",
    "df_flat = pd.json_normalize(json_struct)\n",
    "df_flat.drop([c for c in df_flat.columns if c.endswith(('indexScoreDescription', '.stateDescription', '.provider', '.indexDirection',\n",
    "                                                        '.direction', '.score', '.indexScore',\n",
    "        'sigDevs', 'events', 'secReports', 'projectionValuesCat', 'reports', '.reportId', '.researchReports.title', 'companySnapshot'))],\n",
    "        axis=1, inplace=True)\n",
    "df_flat.columns= [c.replace('instrumentInfo.', '') for c in df_flat.columns]\n",
    "df_flat.columns= [c.replace('technicalEvents.', '') for c in df_flat.columns]\n",
    "df_flat.columns= [c.replace('keyTechnicals.', '') for c in df_flat.columns]\n",
    "df_flat.index = summary.index\n",
    "df_flat = df_flat.T\n",
    "df_flat = pd.concat((df_flat, pd.DataFrame(\n",
    "    {fund['quoteType']['symbol']:\n",
    "    {'annualReportExpenseRatio': fund.get('fundProfile',{}).get('feesExpensesInvestment',{}).get('annualReportExpenseRatio',0)}\n",
    "    for fund in funds.values()}\n",
    ")))\n",
    "display(HTML(\"<style>:root { --jp-notebook-max-width: 96% !important; }</style>\"))\n",
    "\n",
    "noa = len(prices.columns)\n",
    "np.random.seed(NOP)\n",
    "matrix = np.random.random(noa*NOP).reshape(NOP, noa)\n",
    "weights = matrix / matrix.sum(axis=1, keepdims=True)\n",
    "port_ret = prices.div(100).dot(weights.T) # port_ret = ret.dot(weights.T)\n",
    "port_summary = ann_risk_return(port_ret)\n",
    "port_summary[\"Sharpe\"] = (port_summary[\"Return\"].sub(risk_free_return))/port_summary[\"Risk\"]\n",
    "port_summary[\"Sortino\"] = get_sortino(port_ret.iloc[:,:-1])\n",
    "msrp = port_summary.Sharpe.idxmax()\n",
    "msrp1 = port_summary.Sortino.idxmax()\n",
    "msrp_w = weights[msrp, :]\n",
    "msrp1_w = weights[msrp1, :]\n",
    "category = [get_parent(tick) for tick in list(prices.columns[:len(msrp_w)])]\n",
    "summary['category'] = category\n",
    "if len(prices.columns) == len(msrp_w):\n",
    "    prices['sharpe'] = (prices * msrp_w).sum(axis=1)\n",
    "if len(prices.columns) > len(msrp1_w):\n",
    "    msrp1_w = np.append(msrp1_w, 0)\n",
    "    prices['sortino'] = (prices * msrp1_w).sum(axis=1)\n",
    "summary['weight'] = msrp_w*100\n",
    "summary['weight1'] = msrp1_w[:summary.shape[0]]*100\n",
    "pole = \"VOO\" if \"VOO\" in prices.columns else prices.columns[0]\n",
    "summary[\"beta\"] = summary.SystRisk / summary.loc[pole, \"SystRisk\"]\n",
    "summary[\"capm_ret\"] = risk_free_return + (summary.loc[pole, \"Return\"] - risk_free_return) * summary.beta\n",
    "summary[\"alpha\"] = summary.Return - summary.capm_ret\n",
    "# summary = pd.concat((summary, df_flat.iloc[-4:].T), axis=1) # First, we add stopLoss, resistance, support...\n",
    "summary = pd.concat((summary, df_flat.iloc[:-4].T), axis=1) # Next, analysts outlook\n",
    "price_bands() # Calculate price bands\n",
    "sortval = summary['MACD_prc'] * summary['RSI_prc']/100\n",
    "edf = {}\n",
    "for j, v in enumerate(sortval.sort_values(ascending=False).index):\n",
    "    edf[v] = idx.swaplevel(0, 1, axis=1)[v]\n",
    "    edf[v] = calc_ichimoku(edf[v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cb9ee4-3e56-4903-bc48-da35ee45147f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Ichimoku Cloud signals\n",
    "x=-1 # Use latest day's data\n",
    "for indicator in ['MACD', 'RSI']:\n",
    "    summary[f\"{indicator}_prc\"] = 100 - (idx[indicator][:x] < idx[indicator].iloc[x]).mean() * 100\n",
    "\n",
    "bullish = [edf[v].loc[adj_prices.index[x]]['tenkan_sen'] > edf[v].loc[adj_prices.index[x]]['kijun_sen'] for v in adj_prices.columns]\n",
    "trend = [edf[v].loc[adj_prices.index[x]]['Close'] > edf[v].loc[adj_prices.index[x]]['tenkan_sen'] > edf[v].loc[adj_prices.index[x]]['kijun_sen'] or\n",
    "         edf[v].loc[adj_prices.index[x]]['Close'] < edf[v].loc[adj_prices.index[x]]['tenkan_sen'] < edf[v].loc[adj_prices.index[x]]['kijun_sen']\n",
    "         for v in adj_prices.columns]\n",
    "g = px.scatter(\n",
    "    summary, y='RSI_prc', x='MACD_prc', hover_name=summary.index,\n",
    "    color=idx['Adj Close'].pct_change().iloc[x].values*100, color_continuous_scale='RdYlGn', color_continuous_midpoint=0.0,\n",
    "    title='RSI vs MACD Situational frequency', template=template, text=summary.index\n",
    ")\n",
    "\n",
    "kw = dict(\n",
    "    # symbol=np.where(idx['Adj Close'].pct_change().iloc[x] > 0, 'triangle-up', 'triangle-down'),\n",
    "    symbol=np.where(bullish, 'triangle-up', 'triangle-down'),\n",
    "    size=(2*idx['Adj Close'].pct_change().iloc[x] / idx['Adj Close'].pct_change().std())**2+5,\n",
    "    line=dict(width=3, color=idx['RSI'].iloc[x], cmax=2, cmin=-2, colorscale=\"RdYlGn\")\n",
    ")\n",
    "g.update_traces(textfont=dict(color=['rgba(255, 255, 255, 0.25)' if t else 'rgba(255, 255, 255, 0.75)' for t in trend]), textposition='top center', marker=kw)#, hovertemplate=s+'=%{y}<extra></extra>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649c6a0e-a5d3-487b-8e27-d203f1ee2da1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "howmany = 8\n",
    "x_values = sortval.sort_values(ascending=False).index[:howmany]\n",
    "fig = make_subplots(rows=howmany, cols=1, subplot_titles=[f'{x}' for x in x_values])\n",
    "for i, x_value in enumerate(x_values):\n",
    "    single_fig = plot2_ichimoku(d=edf[x_value], ticker_name=x_value)\n",
    "    for trace in single_fig.data:\n",
    "        fig.add_trace(trace, col=1, row=i+1)\n",
    "    fig.update_layout(xaxis={'rangeslider': {'visible': False}, 'title': {'text': 'Date'}})\n",
    "    fig.update_layout(xaxis2={'rangeslider': {'visible': False}, 'title': {'text': 'Date'}})\n",
    "    fig.update_layout(xaxis3={'rangeslider': {'visible': False}, 'title': {'text': 'Date'}})\n",
    "    fig.update_layout(xaxis4={'rangeslider': {'visible': False}, 'title': {'text': 'Date'}})\n",
    "    fig.update_layout(xaxis5={'rangeslider': {'visible': False}, 'title': {'text': 'Date'}})\n",
    "    fig.update_layout(xaxis6={'rangeslider': {'visible': False}, 'title': {'text': 'Date'}})\n",
    "    fig.update_layout(xaxis7={'rangeslider': {'visible': False}, 'title': {'text': 'Date'}})\n",
    "    fig.update_layout(xaxis8={'rangeslider': {'visible': False}, 'title': {'text': 'Date'}})\n",
    "    fig.update_layout(xaxis9={'rangeslider': {'visible': False}, 'title': {'text': 'Date'}})\n",
    "    \n",
    "fig.update_layout(template=template, height=400*min(howmany, len(x_values)))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed447621-fa35-48e0-8e2d-2f2251e7e5f7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "a=[]\n",
    "for fund in funds:\n",
    "    hold_sum = 0\n",
    "    t = None\n",
    "    for t in funds[fund].get('topHoldings',{}).get('holdings',{}):\n",
    "        t['etf'] = fund\n",
    "        t['category'] = summary.loc[fund, 'category']\n",
    "        t['weight']=summary.loc[fund, 'weight' if model=='Sharpe' else 'weight1']\n",
    "        t['holding'] = t['weight'] * t['holdingPercent']\n",
    "        hold_sum += t['holdingPercent']\n",
    "        t['Return'] = summary.loc[fund, 'Return'] #* 100\n",
    "        # t['premium'] = summary.loc[fund, 'premium']\n",
    "        # t['rmse'] = summary.loc[fund, 'rmse']\n",
    "        # t['color'] = t['premium'] / t['rmse']\n",
    "        # t['color'] = summary.loc[fund, 'Return']\n",
    "        t['color'] = 2-summary.loc[fund, 'RSI_prc']/25\n",
    "        a.append(t)\n",
    "    z={}\n",
    "    z['holdingName'] = '<other>'\n",
    "    z['etf'] = fund\n",
    "    z['category'] = summary.loc[fund, 'category']\n",
    "    z['weight']=summary.loc[fund, 'weight' if model=='Sharpe' else 'weight1']\n",
    "    z['holding'] = t['weight'] * (1-hold_sum) if t else 1\n",
    "    z['Return'] = summary.loc[fund, 'Return'] #* 100\n",
    "    # z['premium'] = summary.loc[fund, 'premium']\n",
    "    # z['rmse'] = summary.loc[fund, 'rmse']\n",
    "    z['color'] = 2-summary.loc[fund, 'MACD_prc']/25\n",
    "    a.append(z)\n",
    "\n",
    "tree = pd.DataFrame(a)\n",
    "fig = px.treemap(tree, title=f\"{model} Portfolio Structure\", path=['category', 'etf', 'holdingName'], values='holding', #labels=\"parent\",\n",
    "         hover_name='etf',\n",
    "         hover_data=['Return', 'color'],\n",
    "         color_continuous_midpoint=0, color_continuous_scale=\"Temps\", color='color', range_color=(-2,2))\n",
    "fig.update_layout(margin=dict(l=10, r=10, b=10, t=30), template=template)\n",
    "fig.update_traces(marker=dict(cornerradius=5))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a042f8d1-155e-4c63-919d-c523b1b89f61",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: chop first 26 days\n",
    "titles = []\n",
    "sortval = summary['MACD_prc'] * summary['RSI_prc']/100\n",
    "for title in sortval.sort_values(ascending=False).index:\n",
    "    titles.append(\"{} {:.1f}%\".format(title, sortval.loc[title]))\n",
    "    titles.append(None)\n",
    "kw=dict(\n",
    "    rows=2*summary['MACD_prc'].size,\n",
    "    cols=1,\n",
    "    shared_xaxes=True,\n",
    "    vertical_spacing=.01,\n",
    "    horizontal_spacing=.01,\n",
    "    row_heights=summary['MACD_prc'].size*[300, 100],\n",
    "    subplot_titles=titles\n",
    ")\n",
    "fig = make_subplots(**kw)\n",
    "for j, v in enumerate(sortval.sort_values(ascending=False).index):\n",
    "    kwtop={\"row\":1+2*j, \"col\":1}\n",
    "    kwbottom={\"row\":2+2*j, \"col\":1}\n",
    "\n",
    "    # bollinger bands\n",
    "    g = px.line(edf[v], x=edf[v].index, y='Adj Close')\n",
    "    g.update_traces(line_color='blue', hovertemplate='%{y:.2f}<extra></extra>')\n",
    "    fig.add_trace(g.data[0], **kwtop)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=pd.concat([pd.DataFrame(edf[v].dropna()),  pd.DataFrame(edf[v].dropna())[::-1]]).index,\n",
    "        y=pd.concat([edf[v].dropna()['UBAND'], edf[v].dropna()['LBAND'][::-1]]),\n",
    "        fill='toself',\n",
    "        fillcolor='rgba(64, 64, 64, 0.35)',  # Semi-transparent green\n",
    "        line=dict(color='rgba(255, 255, 255, 0)'),  # Invisible line\n",
    "        name='Bollinger Bands Area',\n",
    "        showlegend=False,\n",
    "        hovertemplate=\"\"\n",
    "    ), **kwtop)\n",
    "\n",
    "    # Buy/ sell signals\n",
    "    for s, n in {'sell': 1, 'buy': -1}.items():\n",
    "        g = px.scatter(edf[v].loc[edf[v].position_ema == n], y=edf[v].loc[edf[v].position_ema == n]['Adj Close'])\n",
    "        kw = dict(symbol=\"triangle-up\" if n==-1 else \"triangle-down\", line=dict(width=1, color=\"green\" if n==-1 else \"red\"))\n",
    "        g.update_traces(marker=kw, hovertemplate=s+'=%{y:.2f}<extra></extra>')\n",
    "        fig.add_trace(g.data[0], **kwtop)\n",
    "        \n",
    "    ### ICHIMOKU CLOUD ###\n",
    "    kwich={'x': edf[v].index, 'type': 'scatter', 'mode': 'lines', 'showlegend': False}\n",
    "    fig.add_trace(go.Scatter(y=np.where(edf[v]['senkou_span_a'] > edf[v]['senkou_span_b'], edf[v]['senkou_span_a'], edf[v]['senkou_span_b']), name='senkou_span_max', line=dict(width=0), **kwich), **kwtop)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        y=edf[v]['senkou_span_b'], \n",
    "        fill='tonexty',\n",
    "        fillcolor='rgba(0, 128, 0, 0.25)',\n",
    "        line=dict(color='rgba(0, 128, 0, 0.1)'),\n",
    "        name='senkou_span_a above',\n",
    "        **kwich), **kwtop)\n",
    "    fig.add_trace(go.Scatter(y=np.where(edf[v]['senkou_span_b'] > edf[v]['senkou_span_a'], edf[v]['senkou_span_b'], edf[v]['senkou_span_a']), name='senkou_span_min', line=dict(width=0), **kwich), **kwtop)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        y=edf[v]['senkou_span_a'], \n",
    "        fill='tonexty',\n",
    "        fillcolor='rgba(128, 0, 0, 0.25)',\n",
    "        line=dict(color='rgba(128, 0, 0, 0.1)'),\n",
    "        name='senkou_span_b above',\n",
    "        **kwich), **kwtop)\n",
    "\n",
    "    # RSI\n",
    "    g = px.line(edf[v], x=edf[v].index, y='RSI')\n",
    "    g.update_traces(hovertemplate='RSI=%{y:.2f}<extra></extra>', line={'width': 1, 'color': 'orange'})\n",
    "    fig.add_trace(g.data[0], **kwbottom)\n",
    "    # Convergence/ divergence\n",
    "    g = px.bar(edf[v], x=edf[v].index, y='MACD')\n",
    "    g.update_traces(marker_color=np.where(edf[v]['MACD'] > 0, 'red', 'green'), hovertemplate='MACD=%{y:.2f}<extra></extra>')\n",
    "    fig.add_trace(g.data[0], **kwbottom)\n",
    "    fig.update_yaxes(type=\"log\", **kwtop)\n",
    "    fig.update_yaxes(range=[-2,2], **kwbottom)\n",
    "\n",
    "kw = dict(\n",
    "    margin=dict(l=10, r=10, b=10, t=10),\n",
    "    template=template,\n",
    "    height=400*j,\n",
    "    hovermode='x unified',\n",
    "    legend_traceorder=\"normal\",\n",
    "    spikedistance=5,\n",
    "    xaxis=dict(spikecolor=\"white\",\n",
    "       spikethickness=.25,\n",
    "       spikedash='dash',\n",
    "       spikemode='toaxis+across+marker',\n",
    "       # range=[edf[v].index[60], edf[v].index[-1]]  # Zoom in from day 26 onward\n",
    "    ),\n",
    "    autosize=True,\n",
    ")\n",
    "fig.update_layout(**kw)\n",
    "fig.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ff4d1a-10d7-45e4-9072-2d0fdf0e08c5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary['url'] = summary.index\n",
    "summary[\"url\"] = summary.apply(lambda row: \"<a href='https://www.etfdb.com/etf/{}/#holdings' target='_blank'>{}</a>\".format(row.url, row.url), axis=1)\n",
    "display(HTML(summary.infer_objects(copy=False).fillna('').T.style.apply(h_bull, axis=1).apply(h_bear, axis=1).apply(h_min, axis=1).apply(h_max, axis=1).to_html(escape=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d3dc1d-5b1e-4faa-9696-2b92585bb140",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Sharpe vs Sortino ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093a0d04-03ae-499f-a81b-672c3c744fde",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, sharey=True, figsize=(16, 6))\n",
    "axes[0].scatter(summary.loc[:, \"Risk\"], summary.loc[:, \"Return\"]*100, s=10, marker=\"x\", c=\"lime\")\n",
    "axes[0].scatter(port_summary.loc[:, \"Risk\"], port_summary.loc[:, \"Return\"]*100, s=8, c=port_summary.loc[:, \"Sharpe\"], cmap=\"coolwarm\",\n",
    "    vmin=port_summary.Sharpe.min(), vmax=port_summary.loc[msrp].Sharpe, alpha=.7)\n",
    "for i in summary.index:\n",
    "    axes[0].annotate(i, xy=(summary.loc[i, \"Risk\"]+0.0002, summary.loc[i, \"Return\"]*100+.5), size=8, c=\"lime\")\n",
    "\n",
    "axes[1].scatter(summary.loc[:, \"Risk\"], summary.loc[:, \"Return\"]*100, s=10, marker=\"x\", c=\"lime\")\n",
    "axes[1].scatter(port_summary.loc[:, \"Risk\"], port_summary.loc[:, \"Return\"]*100, s=8, c=port_summary.loc[:, \"Sortino\"], cmap=\"coolwarm\",\n",
    "    vmin=port_summary.Sortino.min(), vmax=port_summary.loc[msrp1].Sortino, alpha=.7)\n",
    "for i in summary.index:\n",
    "    axes[1].annotate(i, xy=(summary.loc[i, \"Risk\"]-0.1, summary.loc[i, \"Return\"]*100-1.5), size=8, c=\"lime\")\n",
    "\n",
    "axes[0].set_xlabel('Risk(std)')\n",
    "axes[0].set_ylabel('Return')\n",
    "axes[1].set_xlabel('Risk(std)')\n",
    "axes[1].set_ylabel('Return')\n",
    "\n",
    "axes[0].set_title(f\"Sharpe Ratio: ({port_summary.loc[msrp].Return*100:.1f}% return {str(start)[:4]}-{end[:4]})\")\n",
    "axes[1].set_title(f\"Sortino Ratio: ({port_summary.loc[msrp1].Return*100:.1f}% return {str(start)[:4]}-{end[:4]})\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d452b2d-6a71-45d6-a886-d06c9a1e3f20",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Today's liquidation\n",
    "s0 = 0\n",
    "for v in range(100):\n",
    "    ploc = int(v*(prices.shape[0]/100))\n",
    "    df = (prices/prices.iloc[ploc]).dropna()\n",
    "    df['Sharpe'], df['Sortino'] = (df.iloc[:,:len(msrp_w)] * msrp_w).sum(axis=1), (df.iloc[:,:len(msrp1_w)] * msrp1_w).sum(axis=1)\n",
    "    ratios = (ann_risk_return(df.iloc[ploc:,-2:])['Return']*100)[-2:].values\n",
    "    s0 = s0 + 1 if ratios[0] > ratios[1] else s0 -1\n",
    "model = 'Sharpe' if s0 > 0 else 'Sortino'\n",
    "print(f\"{abs(s0)}% of samples in favor of {model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd917d8-c177-46a5-9a50-691d1c9200da",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Range of liquidations, start prices\n",
    "s0 = 0\n",
    "for v in range(99, 0, -1):\n",
    "    ploc = int(v * (prices.shape[0] / 100))\n",
    "    if ploc < 2:\n",
    "        continue\n",
    "    df = (prices / prices.iloc[0]).dropna()\n",
    "    df['Sharpe'], df['Sortino'] = (df.iloc[:,:len(msrp_w)] * msrp_w).sum(axis=1), (df.iloc[:,:len(msrp1_w)] * msrp1_w).sum(axis=1)\n",
    "    ratios = (ann_risk_return(df.iloc[:ploc,-2:])['Return']*100)[-2:].values\n",
    "    s0 = s0 + 1 if ratios[0] > ratios[1] else s0 -1\n",
    "model = 'Sharpe' if s0 > 0 else 'Sortino'\n",
    "print(f\"{abs(s0)}% of samples in favor of {model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee438d45-1191-4b7f-a277-dfd19487359b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=1, cols=2, subplot_titles=(\"Price Correlation\", \"% Change Correlation\"))#, \"Price Covariance\"))\n",
    "kw = {\n",
    "    'x':prices.columns,\n",
    "    'y':prices.columns,\n",
    "    'colorscale': \"Jet\",\n",
    "    'showscale':False,\n",
    "}\n",
    "f1 = go.Heatmap(name='Correlation', z=prices.corr(), zmid=0.0, **kw)\n",
    "f2 = go.Heatmap(name='% Changes Correlation', z=prices.pct_change().corr(), zmid=0.0, **kw)\n",
    "# f3 = go.Heatmap(name='Price Covariance', z=prices.cov(), zmid=0.0, **kw)\n",
    "\n",
    "fig.add_trace(f1, row=1, col=1)\n",
    "fig.add_trace(f2, row=1, col=2)\n",
    "# fig.add_trace(f3, row=1, col=3)\n",
    "fig.update_layout(template=template, height=500, width=1000, margin=dict(l=10, r=10, b=10, t=20))\n",
    "fig.update_yaxes(autorange=\"reversed\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f6bc3f-9c5f-4a39-8b6b-5f2c341ceeff",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "prices.index = pd.to_datetime(prices.index)\n",
    "ax={'sharpe': ax1, 'sortino': ax2}\n",
    "for i, v in ax.items():\n",
    "    p_tr = prices[i].resample(\"ME\").last()\n",
    "    p_ret = np.log(p_tr / p_tr.shift()).dropna().to_frame()\n",
    "    p_ret.columns = [\"Return\"]\n",
    "    windows = [year for year in range(p_ret.index.size, 0, -1)]\n",
    "    for period in windows:\n",
    "        p_ret[\"#{}\".format(period)] = p_ret.Return.rolling(period).mean()\n",
    "    triangle = p_ret.drop(columns = [\"Return\"])\n",
    "    triangle.index = triangle.index.to_period('M')\n",
    "    sns.heatmap(triangle, annot=False, cmap=\"RdYlGn\", vmin=-0.2/12, vmax=0.2/12, center=0, cbar=False, ax=v)\n",
    "\n",
    "# plt.figure(figsize=(80,50))\n",
    "plt.tick_params(axis = \"y\", labelright =True, labelleft=False, grid_alpha=.5)\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a631b4-8670-434c-b55d-4fb3892e9e4a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "v=0\n",
    "log=True\n",
    "df = (prices/prices.iloc[int(v*(prices.shape[0]/100))]).dropna()\n",
    "ar = ann_risk_return(df.iloc[int(v*(prices.shape[0]/100)):])\n",
    "layout = dict(\n",
    "    title=\"Normalized Returns since {}. Sharpe: {:.1f}%. Sortino: {:.1f}%. Max: {:.1f} ({})\".format(\n",
    "        str(prices.iloc[int(v*(prices.shape[0]/100))].name)[:10],\n",
    "        ar.iloc[-2]['Return']*100,\n",
    "        ar.iloc[-1]['Return']*100,\n",
    "        ar.Return.iloc[ar.Return.argmax()]*100,\n",
    "        ar.iloc[ar.Return.argmax()].name\n",
    "    ),\n",
    "    log_y=True,\n",
    "    template=template\n",
    ")\n",
    "px.line(df, **layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c4b967-5152-45c1-8ad9-84f9f7432e28",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Pricing ##"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4be6beac-ccb1-40a6-9916-e506071f0549",
   "metadata": {},
   "source": [
    "slider = widgets.IntSlider(min=1, value=42) # 60 calendar days\n",
    "def print_val(v):\n",
    "    print(f\"Trading days: {v} {adj_prices.rolling(v).min().iloc[-1,:]}\")\n",
    "    return (prices.pct_change(v)*100).iplot(title=f\"Sliding Returns over {v} days\", theme='solar')\n",
    "interact(print_val,v=slider);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94f5249-540e-4330-a33c-2452bbb89efc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(x=summary.index, y=summary['SystRisk'], name='SystRisk'))\n",
    "fig.add_trace(go.Bar(x=summary.index, y=summary['UnsystRisk'], name='UnsystRisk'))\n",
    "fig.update_layout({\n",
    "    # 'barmode': 'stack',\n",
    "    'title': \"Risks\",\n",
    "    'template': template,\n",
    "    'yaxis': {'title_text': \"Risk\"}\n",
    "})\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ff1198-88c0-43bc-87a6-6246ae1a0206",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "options = ['alpha', 'beta', 'Risk', 'SystRisk', 'UnsystRisk', 'TotalRisk', 'Sharpe', 'capm_ret']\n",
    "slider = widgets.IntSlider(min=1, max=len(options))\n",
    "def print_val(v):\n",
    "    titles = (f\"Sharpe Portfolio Components Return vs {options[v-1]}: {port_summary.loc[msrp].Return*100:.1f}% {start.strftime('%Y')}-{end[:4]}\",\n",
    "            f\"Sortino Portfolio Components Return vs {options[v-1]}: {port_summary.loc[msrp1].Return*100:.1f}% {start.strftime('%Y')}-{end[:4]}\")\n",
    "    fig = make_subplots(rows=2, cols=1, shared_xaxes=True, shared_yaxes=True, subplot_titles=titles)\n",
    "    kw = {\n",
    "        'hovertext': summary.index,\n",
    "        'x':summary[options[v-1]],\n",
    "        'y':summary['Return'],\n",
    "        'mode':'markers',\n",
    "        'marker':dict(size=summary['weight']+1, color=pd.factorize(summary['category'])[0]),\n",
    "        'showlegend': False,\n",
    "    }\n",
    "    kw1 = {\n",
    "        'hovertext': summary.index,\n",
    "        'x':summary[options[v-1]],\n",
    "        'y':summary['Return'],\n",
    "        'mode':'markers',\n",
    "        'marker':dict(size=summary['weight1']+1, color=pd.factorize(summary['category'])[0]),\n",
    "        'showlegend': False,\n",
    "    }\n",
    "    f1 = go.Scatter(**kw)\n",
    "    f2 = go.Scatter(**kw1)\n",
    "    \n",
    "    fig.add_trace(f1, row=1, col=1)\n",
    "    fig.add_trace(f2, row=2, col=1)\n",
    "    fig.update_layout(template=template, height=500, width=1000, margin=dict(l=10, r=10, b=10, t=30))\n",
    "    return fig\n",
    "\n",
    "interact(print_val,v=slider);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a656ec9-d8d4-4fa0-83a9-5abb7270e1a3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Sectors ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c99ee7c-8173-44f6-b810-9056772c2a61",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sector coverage in funds\n",
    "for i in range(summary.shape[0]):\n",
    "    try: # fund_sector_weightings fails for certain funds, need to find one that succeeds\n",
    "        if not any(tickers[summary.index[i]].fund_sector_weightings):\n",
    "            continue\n",
    "    except:\n",
    "        continue\n",
    "    break\n",
    "snames = tickers[summary.index[i]].fund_sector_weightings.index\n",
    "sectors=pd.DataFrame([\n",
    "    funds[fund][\"topHoldings\"]['sectorWeightings'] if funds[fund].get(\"topHoldings\",{}).get('sectorWeightings') else len(snames) * [None]\n",
    "    for fund in funds\n",
    "], index=summary.index, columns=snames).replace(to_replace=[None], value=[dict({'none': 0.0})])\n",
    "for c in sectors.columns:\n",
    "    sectors[c] = [v for d in sectors[c].values for v in d.values()]\n",
    "sectors = sectors.T\n",
    "sectors['sharpe']=(sectors * msrp_w).sum(axis=1)\n",
    "sectors['sortino']=(sectors * msrp1_w).sum(axis=1)\n",
    "sectors.sort_index(inplace=True)\n",
    "px.imshow(sectors*100, template=template, title='Top Sectors')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b3fac0-eeea-4355-b1a6-f25a62181add",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Overlaps ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5289f6aa-7250-42cb-83ff-50a892a826f7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "g = net.Network(notebook=True, bgcolor='#111111', font_color='white', width=\"100%\", height=\"800px\")#, cdn_resources='in_line')\n",
    "# g.repulsion()\n",
    "g.physics = \"forceAtlas2Based\"\n",
    "# g.inherit_edge_colors(False)\n",
    "nxg=nx.complete_graph(0)\n",
    "for n in summary.index: # FIXME: colors of edges\n",
    "    kw = {'label':n, 'shape':'box'} #'size':abs(summary.loc[n, 'Return'])*100\n",
    "    kw['title'] = textwrap.fill(funds[n]['summaryProfile'].get('longBusinessSummary', funds[n]['summaryProfile'].get('description')), 60)\n",
    "    if summary.loc[n, 'Return'] < 0:\n",
    "        kw['color'] = 'red'\n",
    "    kw['borderWidth'] = abs(summary.loc[n]['Return']) * 100\n",
    "    kw['group'] = summary.loc[n]['category']\n",
    "    nxg.add_node(n, **kw)\n",
    "    for h in funds[n].get('topHoldings',{}).get('holdings',{}):\n",
    "        nxg.add_node(h['symbol'], label=h['holdingName'], shape='text')\n",
    "        nxg.add_edge(n, h['symbol'], value=h['holdingPercent'], title=f\"{100*h['holdingPercent']:.1f}%\")\n",
    "g.from_nx(nxg)\n",
    "g.show(\"overlaps.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be5e3ca-40ae-4a03-8a90-582ed7b7f2e7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Obsolete"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4dcc3c80-689b-40ab-8a41-fc11206168bd",
   "metadata": {},
   "source": [
    "%%time\n",
    "cols = 2\n",
    "fig = make_subplots(rows=int((len(prices.columns)+1)/cols), cols=cols, shared_xaxes='all', vertical_spacing=.05, horizontal_spacing=.05,\n",
    "    subplot_titles=prices.columns, column_width=[1000/cols for i in range(cols)])\n",
    "premiums, rmses, currents, predicts, counter = [], [], [], [], 0\n",
    "for fund in prices.columns:\n",
    "    data, dataset, training_data_len = get_data(fund)\n",
    "    x_train, y_train, scaler, scaled_data = get_train()\n",
    "    pred_model = get_model(x_train, y_train)\n",
    "    predictions, rmse = get_predictions(scaler, scaled_data)\n",
    "    \n",
    "    rescale = 1 if fund in ['sharpe', 'sortino'] else idx.loc[start, 'Adj Close'][fund] / 100\n",
    "    train, valid = data[:training_data_len] * rescale, data[training_data_len:] * rescale\n",
    "    valid['Predictions'] = predictions * rescale\n",
    "    data[fund] = data[fund] * rescale\n",
    "    premium = valid.iloc[-1, 0]/valid.iloc[-1, 1] * 100 - 100\n",
    "    premiums.append(premium)\n",
    "    rmses.append(rmse)\n",
    "    currents.append(valid.iloc[-1, 0])\n",
    "    predicts.append(valid.iloc[-1, 1])\n",
    "\n",
    "    if fund in idx['LBAND'].columns:\n",
    "        fig_l = px.line(idx['LBAND'].filter([fund]), x=idx['LBAND'].filter([fund]).index, y=idx['LBAND'].filter([fund]).columns[0])\n",
    "        fig_u = px.line(idx['UBAND'].filter([fund]), x=idx['UBAND'].filter([fund]).index, y=idx['UBAND'].filter([fund]).columns[0])\n",
    "        fig_l.update_traces(line_color='#c0c0c0', line_width=1, hovertemplate='LBAND=%{y}<extra></extra>')\n",
    "        fig_u.update_traces(line_color='#c0c0c0', line_width=1, hovertemplate='UBAND=%{y}<extra></extra>')\n",
    "        fig.add_trace(fig_u.data[0], row=counter//cols+1, col=counter % cols + 1);\n",
    "    \n",
    "    fig_b = px.line(data, x=data.index, y=data.columns[0])\n",
    "    fig_b.update_traces(line_color='#0000ff', line_width=1, hovertemplate='Adj Close=%{y}<extra></extra>')\n",
    "    fig_r = px.line(valid, x=valid.index, y='Predictions')\n",
    "    fig_r.update_traces(line_color='#ff0000' if premium>0 else '#00ff00', line_width=abs(premium)+1, opacity=min([1, (abs(premium)/rmse) ** .5]), hovertemplate='Predictions=%{y}<extra></extra>')\n",
    "    fig.add_trace(fig_r.data[0], row=counter//cols+1, col=counter % cols + 1);\n",
    "    fig.add_trace(fig_b.data[0], row=counter//cols+1, col=counter % cols + 1);\n",
    "    if fund in idx['LBAND'].columns:\n",
    "        fig.add_trace(fig_l.data[0], row=counter//cols+1, col=counter % cols + 1); # So it'd be at the bottom of hover screen\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    target = ((idx.Low / idx.Open).quantile(0.3) * idx.Open).iloc[-1][fund] if not fund in ['sharpe', 'sortino'] else 0\n",
    "    text = f\"{fund}: {premium:.1f}% premium ({rmse:.1f} rmse). Predict: {valid.iloc[-1, 1]:.2f}.\"\n",
    "    if not fund in ['sharpe', 'sortino']:\n",
    "        text = text + f\" Buy: {target:.2f}\"\n",
    "    fig.layout['annotations'][counter].update({\"text\": text})\n",
    "    fig.update_yaxes(type=\"log\")\n",
    "\n",
    "    fig.update_layout(height=60*len(prices.columns)+60*counter, width=1450, margin=dict(l=10, r=10, b=10, t=30), template=template,\n",
    "            xaxis=dict(spikecolor=\"white\", spikethickness=.25, spikedash='dash', spikemode='toaxis+across+marker', spikesnap='cursor'),\n",
    "        spikedistance=4, hovermode='x unified', legend_traceorder=\"normal\")\n",
    "\n",
    "    counter += 1\n",
    "    fig.show();\n",
    "\n",
    "summary[\"current\"] = currents[:summary.shape[0]]\n",
    "summary[\"predict\"] = predicts[:summary.shape[0]]\n",
    "summary[\"premium\"] = premiums[:summary.shape[0]]\n",
    "summary[\"rmse\"] = rmses[:summary.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23460c77-38d5-4fde-973c-faa4fbc455b6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ms = range(20, 101, 10)\n",
    "dfmd = pd.DataFrame(index = ms, columns=idx['Adj Close'].columns)\n",
    "\n",
    "for finish in ms:\n",
    "    n, best = min([3, len(idx['Adj Close'].columns)//2]), {c:0 for c in idx['Adj Close'].columns}\n",
    "    for v in range(100):\n",
    "        t0 = int(v * (prices.shape[0] * finish / 100 / 100)) # Starting time for comparison\n",
    "        df = (prices.iloc[:int((prices.shape[0] * finish / 100))] / prices.iloc[t0]).dropna() # DataFrame normalized against Starting time prices\n",
    "        if t0 + 1 >= df.shape[0]:\n",
    "            continue\n",
    "        ratios = ann_risk_return(df.iloc[int(v * (df.shape[0] / 100)):])['Return'][:-2] * 100\n",
    "        for x in ratios.nlargest(n).index:\n",
    "            best[x] = 1 if not x in best else best[x]+1\n",
    "    summary['Top'] = [best[x] for x in sorted(best)] # Sample 100 intervals' to date for top N returns\n",
    "    weight = 'weight' if model == 'Sharpe' else 'weight1'\n",
    "    dfmd.loc[finish] = [best[x] for x in sorted(best)]\n",
    "    \n",
    "dfmd.index = [str(prices.iloc[int(prices.shape[0] * x / 100)].name)[:10] for x in range(10, 100, 10)]\n",
    "px.imshow(dfmd.T, template=template, color_continuous_scale=px.colors.sequential.Viridis, color_continuous_midpoint=55,\n",
    "          title=f\"In Top {n} Performers {dfmd.index[0]} ... {dfmd.index[-1]}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7b26b6d2-b285-4a55-af78-044b26679dfc",
   "metadata": {
    "tags": []
   },
   "source": [
    "slider = widgets.IntSlider(min=20, max=100, value=100, step=20)\n",
    "def print_val(finish):\n",
    "    n, best = min([3, len(idx['Adj Close'].columns)//2]), {c:0 for c in idx['Adj Close'].columns}\n",
    "    for v in range(100):\n",
    "        t0 = int(v * (prices.shape[0] * finish / 100 / 100)) # Starting time for comparison\n",
    "        df = (prices.iloc[:int((prices.shape[0] * finish / 100))] / prices.iloc[t0]).dropna() # DataFrame normalized against Starting time prices\n",
    "        ratios = ann_risk_return(df.iloc[int(v * (df.shape[0] / 100)):])['Return'][:-2] * 100\n",
    "        largest_values = ratios.nlargest(n)\n",
    "        for x in largest_values.index:\n",
    "            best[x] = 1 if not x in best else best[x]+1\n",
    "    weight = 'weight' if model == 'Sharpe' else 'weight1'\n",
    "    return px.bar(summary, title=f\"In Top {n} Performers {str(df.iloc[0].name)[:10]} ... {str(df.iloc[-1].name)[:10]}\", color=category,\n",
    "                  y=[best[x] for x in sorted(best)], template=template, opacity=[(x/max(summary[weight]))**.5 for x in summary[weight]])\n",
    "interact(print_val,finish=slider);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85261cf4-97af-4d0a-b663-43324e0d7790",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Recommendations ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa33c900-3e93-4919-b5a6-79147379c745",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Price correlation\n",
    "def reg_coef(x, y, label=None, color=None, cmap=None, **kwargs):\n",
    "    ax = plt.gca()\n",
    "    r, _ = stats.pearsonr(x, y)\n",
    "    norm = plt.Normalize(-1, 1)\n",
    "    cmap = cmap if not cmap is None else plt.cm.coolwarm\n",
    "    ax.annotate(f\"{r:.2f}\", xy=(0.5, 0.5), xycoords='axes fraction', ha='center', fontsize=16, bbox={'facecolor': cmap(norm(r)), 'alpha': r**4})\n",
    "    ax.set_axis_off()\n",
    "\n",
    "return_fig = sns.PairGrid(prices)\n",
    "# Using map_upper we can specify what the upper triangle will look like.\n",
    "return_fig.map_upper(plt.scatter, color='purple')\n",
    "return_fig.map_upper(reg_coef, cmap=plt.get_cmap('PiYG'))\n",
    "\n",
    "# We can also define the lower triangle in the figure, inclufing the plot type (kde) or the color map (BluePurple)\n",
    "return_fig.map_lower(sns.kdeplot, cmap='cool_d')\n",
    "# Finally we'll define the diagonal as a series of histogram plots of the daily return\n",
    "return_fig.fig.suptitle('Price Correlation', fontsize=24)\n",
    "return_fig.map_diag(plt.hist, bins=24);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bb6c51-a371-490e-aef5-ad58a1bd8159",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379ddc03-860b-4682-a15a-83a47038af3f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Screener"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e6d1c3-fb11-4e6e-920c-38001bf411c4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "droplist = \" \".join((TEST, \" \".join((categories.values()))))\n",
    "shortlist = []\n",
    "for r in recommendations.values():\n",
    "    for v in r.values():\n",
    "        if v=='No data found':\n",
    "            continue\n",
    "        for rec in v['recommendedSymbols']:\n",
    "            if not (rec['symbol'] in droplist):\n",
    "                shortlist.append(rec['symbol'])\n",
    "profiles = {n:Ticker(n).fund_profile[n] for n in shortlist}\n",
    "for prop in ['maxAge', 'styleBoxUrl']:\n",
    "    for k,v in profiles.items():\n",
    "        if prop in v:\n",
    "            del v[prop]\n",
    "shortlist = [p for p, v in profiles.items() if 'categoryName' in v and not 'Leveraged' in v['categoryName']]\n",
    "\" \".join(sorted({*shortlist}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070ff3a9-8b21-4fc0-a95a-23bf9c8f2990",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Recommendations\n",
    "g = net.Network(notebook=True, bgcolor='#111111', font_color='white', width=\"100%\", height=\"800px\")#, cdn_resources='in_line')\n",
    "g.repulsion()\n",
    "g.physics = \"forceAtlas2Based\"\n",
    "nxg=nx.complete_graph(0)\n",
    "for n in summary.index:\n",
    "    kw = {'label':n, 'shape':'box'}\n",
    "    kw['group'] = summary.loc[n]['category']\n",
    "    kw['title'] = textwrap.fill(funds[n]['summaryProfile'].get('longBusinessSummary', funds[n]['summaryProfile'].get('description')), 60)\n",
    "    nxg.add_node(n, **kw)\n",
    "    if list(recommendations[n].values()) == ['No data found']:\n",
    "        continue\n",
    "    for h in list(recommendations[n].values())[0]['recommendedSymbols']:\n",
    "        if not h['symbol'] in shortlist:\n",
    "            continue\n",
    "        nxg.add_node(h['symbol'], label=h['symbol'], shape='text', title=json.dumps(profiles[h['symbol']], indent=2))\n",
    "        nxg.add_edge(n, h['symbol'], value=h['score'], title=100*h['score'])\n",
    "g.from_nx(nxg)\n",
    "g.show(\"recommendations.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd504830-d39a-436b-b2a7-7b40ab7f9cd3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "s = Screener()\n",
    "print([x for x in s.available_screeners if 'etf' in x and not 'asia' in x and not 'europe' in x])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a7d6e682-185e-436f-b7f1-71801cfe0b7b",
   "metadata": {},
   "source": [
    "print(json.dumps(s.get_screeners(['top_etfs_us', 'cheapest_etfs', 'fifty_two_wk_losers_etfs', 'precious_metal_etfs', 'top_performing_etfs'], 5), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52edc60d-7d81-4058-a909-c54e05a02062",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "screener = ['fifty_two_wk_losers_etfs', 'cheapest_etfs', 'top_etfs_us'] #'top_performing_etfs', 'precious_metal_etfs'\n",
    "def g(row):\n",
    "    return [str(r) for r in row.values]\n",
    "    \n",
    "def bold_row(row):\n",
    "    return ['font-weight: bold' if 'ChangePercent' in row.name else '' for v in row]\n",
    "\n",
    "def bold_index(s):\n",
    "    return '<b>{}</b>'.format(s)\n",
    "\n",
    "def h_hi(row):\n",
    "    return ['background-color: lightgreen']*len(row.values) if 'ChangePercent' in row.name else ['']*len(row.values)\n",
    "\n",
    "droprows=[\"shortName\", 'exchange', 'firstTradeDateMilliseconds', 'messageBoardId', 'dividendDate', 'fiftyTwoWeekLowChangePercent',\n",
    "          'fiftyTwoWeekHighChangePercent', 'fiftyDayAverageChangePercent', 'twoHundredDayAverageChangePercent', 'fiftyTwoWeekLowChange',\n",
    "          'fiftyTwoWeekHighChange', 'regularMarketChange', 'isEarningsDateEstimate', 'postMarketChangePercent', 'askSize', 'bidSize',\n",
    "          'ipoExpectedDate', 'epsTrailingTwelveMonths', 'sharesOutstanding', 'bookValue', 'marketCap', 'netAssets']\n",
    "quotes = [i for q in s.get_screeners(screener, 48).values() for i in q['quotes'] if not i['symbol'] in droplist]\n",
    "df = pd.json_normalize(quotes).set_index('symbol').T\n",
    "df.drop(df.index[:7], inplace=True)\n",
    "df.drop([c for c in df.index if 'Time' in c], inplace=True)\n",
    "df.dropna(axis=1, subset=['longName'], inplace=True)\n",
    "\n",
    "regex = re.compile('|'.join(['everage', \"Ether\", 'Bitcoin', 'Bond', \"Ultra\", \"Short\", \"Long\", 'Hedge', 'Option', 'Covered Call', 'Treasury',\n",
    "                             \"Trust\", \"Daily\", \"Monthly\", 'Weekly', 'Asia', 'China', 'Emerging', 'iShares MSCI']))\n",
    "df.drop(columns=df.columns[df.loc['longName'].str.contains(regex)], axis=1, inplace=True)\n",
    "\n",
    "for i in df.index:\n",
    "    if 1 == len(set(g(df.loc[i,:]))):\n",
    "        droprows.append(i)\n",
    "df.drop(droprows, inplace=True, errors='ignore')\n",
    "df = df.sort_values(by=['fiftyTwoWeekChangePercent'], axis=1, ascending=False)\n",
    "df = df.fillna('')\n",
    "\n",
    "df.drop(droplist, axis=1, errors='ignore', inplace=True)\n",
    "df.head(60).style.apply(h_max, axis=1).apply(h_min, axis=1).apply(bold_row, axis=1).apply(h_hi, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819f3d97-5547-4a8f-81d4-1f1c8628092f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\" \".join(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c879ca-7f45-4ec9-8e26-e0f0be6637d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Algo Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0544b96e-a9cc-4112-9d48-42c24e3e4c66",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "algo=(1 + idx['Adj Close'].pct_change() * idx['position_ema'].shift(1)).cumprod()\n",
    "px.line(algo, template=template, log_y=True, title=\"Algo EMA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44aa2861-4436-481b-b75b-4a21ee72d135",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "algo=(1 + idx['Adj Close'].pct_change() * idx['position_rsi'].shift(1)).cumprod()\n",
    "px.line(algo, template=template, log_y=True, title=\"Algo RSI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693ebd16-2128-41ec-8db8-fd9194b6097f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c16ace-e9ca-42b0-a86b-1cd8129288c4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# idx = calc_ichimoku(idx)\n",
    "v = 'CRPT'\n",
    "edf[v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feecc9f7-12cf-492e-8ca5-80cd19eabc0e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_positions_ichimoku(d):\n",
    "    global idx\n",
    "    columns = d['Low'].columns\n",
    "    # Adding signals for buy/ sell\n",
    "    condition = np.where(\n",
    "        (d['tenkan_sen'] > d['kijun_sen']) & (d['Close'] > d['tenkan_sen']),\n",
    "        1, 0\n",
    "    )\n",
    "    sgn = pd.DataFrame(condition, columns=columns, index=d.index)\n",
    "    sgn.columns = pd.MultiIndex.from_product([['signal_ichimoku'], columns])\n",
    "    pos = sgn.diff().fillna(0)\n",
    "    pos.columns = pd.MultiIndex.from_product([['position_ichimoku'], columns])\n",
    "    idx.drop(columns='signal_ichimoku', inplace=True, errors='ignore')\n",
    "    idx.drop(columns='position_ichimoku', inplace=True, errors='ignore')\n",
    "    idx = idx.join(pos)\n",
    "    idx = idx.join(sgn)\n",
    "calc_positions_ichimoku(idx)\n",
    "\n",
    "algo=(1 + idx['Adj Close'].pct_change() * idx['position_ichimoku'].shift(1)).cumprod()\n",
    "px.line(algo, template=template, log_y=True, title=\"Algo Ichimoku\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd40560f-c9d9-4e97-961d-4741a16951f9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "signals = ['signal_ema', 'signal_rsi', 'signal_ichimoku']\n",
    "idx[signals][:].swaplevel(0, 1, axis=1)['CRPT'].tail(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e45dd3e-3c33-4998-9e10-91662301fce1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4546d0d5-8c29-4f60-a668-917adf077d0d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9e528a-053d-4a99-8975-654a1be8f737",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda-fin:Python",
   "language": "python",
   "name": "conda-env-.conda-fin-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
